{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.8.19 (default, Mar 20 2024, 15:27:52) \n",
      "[Clang 14.0.6 ]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=8, micro=19, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"Python version\")\n",
    "print(sys.version)\n",
    "print(\"Version info.\")\n",
    "print(sys.version_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:36:16.549049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import nbformat\n",
    "\n",
    "def save_checkpoint(notebook_name):\n",
    "    checkpoint_dir = \"./checkpoints\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    # Load current notebook\n",
    "    with open(f\"./{notebook_name}\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    # Create a checkpoint filename with timestamp\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    checkpoint_name = f\"{os.path.basename(notebook_name).replace('.ipynb', '')}_checkpoint_{timestamp}.ipynb\"\n",
    "\n",
    "    # Save the checkpoint\n",
    "    with open(f\"{checkpoint_dir}/{checkpoint_name}\", 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(nb, f)\n",
    "\n",
    "    print(f\"Checkpoint saved as {checkpoint_name}\")\n",
    "    return checkpoint_name\n",
    "\n",
    "def load_checkpoint(checkpoint_name):\n",
    "    \"\"\"\n",
    "    Load a checkpointed notebook and display its contents in the current Jupyter environment.\n",
    "    \"\"\"\n",
    "    with open(f\"./checkpoints/{checkpoint_name}\", 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    return nb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T08:44:30.216467Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plate2Recipe NLP Model: \n",
    "Recipe Generation from Ingredients List using GPT-2 and TF-IDF Similarity Matching\n",
    "\n",
    "@Author: Nellie Cordova"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NLP Model\n",
    "- Assume list of ingredients is provided, use this to generate the recipe. \n",
    "- Match input list of ingredients with the ingredients in the dataset and generate the recipe\n",
    "- Approach:\n",
    "        -- TF-IDF: Vectorization of ingredients.\n",
    "        -- Cosine Similarity: to find the recipe in the dataset that has the highest similarity to the provided ingredients.\n",
    "        -- GPT2 model: Generate the recipe based on the matched recipe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\r\n",
      "  Using cached bayesian_optimization-1.4.3-py3-none-any.whl.metadata (543 bytes)\r\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Applications/anaconda3/envs/p2r/lib/python3.8/site-packages (from bayesian-optimization) (1.24.3)\r\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/nc/.local/lib/python3.8/site-packages (from bayesian-optimization) (1.10.1)\r\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /Applications/anaconda3/envs/p2r/lib/python3.8/site-packages (from bayesian-optimization) (1.3.0)\r\n",
      "Collecting colorama>=0.4.6 (from bayesian-optimization)\r\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Applications/anaconda3/envs/p2r/lib/python3.8/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Applications/anaconda3/envs/p2r/lib/python3.8/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.2.0)\r\n",
      "Using cached bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\r\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\r\n",
      "Installing collected packages: colorama, bayesian-optimization\r\n",
      "Successfully installed bayesian-optimization-1.4.3 colorama-0.4.6\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "!pip install bayesian-optimization\n",
    "from bayes_opt import BayesianOptimization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:36:32.054669Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Collection and Preprocessing\n",
    "\n",
    "- Data loading: *use full_dataset.csv for NLP* (https://drive.google.com/drive/folders/1ui_zS11_ENZTCNLUsgg_UwAYr-ZaLbac)\n",
    "- Data cleaning\n",
    "- Data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_MPS_HIGH_WATERMARK_RATIO set to: 0.0\n"
     ]
    }
   ],
   "source": [
    "# MPS memory management - Used to solve RuntimeError: MPS backend out of memory\n",
    "# source: https://pnote.eu/notes/pytorch-mac-setup/\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "\n",
    "# Check that the environment variable is set correctly\n",
    "print(\"PYTORCH_MPS_HIGH_WATERMARK_RATIO set to:\", os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:36:38.954476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Set device to maximize performance\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "device = torch.device(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:41:31.525600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:41:35.131583Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Helper function to clear unused memory\n",
    "def clear_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    elif torch.backends.mps.is_available():\n",
    "        torch.mps.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:41:47.100522Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "clear_memory()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:41:48.008187Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "user_ingredients = ['avocado', 'rice', 'shrimp', 'tomato']\n",
    "dataset_path = './data/full_dataset.csv'\n",
    "pickle_path = './data/recipes.pickle'\n",
    "\n",
    "n_recipes = 100\n",
    "model_path = \"gpt2\"\n",
    "best_model_path = f'./models/best_gpt2_model_{n_recipes}'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:41:53.362190Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath).drop(['Unnamed: 0'], axis=1)\n",
    "    return data\n",
    "\n",
    "recipes = load_data(dataset_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:42:45.053018Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.data_utils import save_pickle, load_pickle\n",
    "save_pickle(recipes, pickle_path)\n",
    "dat = load_pickle(pickle_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                        title  \\\n0        Crisp Rosemary-Parmesan Garlic Bread   \n1  Bean and Vegetable Soup, First Time Around   \n2                           Persimmon Pudding   \n3                    Courgette Chocolate Cake   \n4                               Sausage Gravy   \n\n                                         ingredients  \\\n0  [\"2 tablespoons butter, room temperature\", \"2 ...   \n1  [\"1/4 cup extra virgin olive oil\", \"4 slices b...   \n2  [\"1 stick margarine\", \"2 c. persimmon\", \"2 c. ...   \n3  [\"125 g butter\", \"1 cup brown sugar\", \"1/2 cup...   \n4  [\"1/2 lb. bulk sausage\", \"2 Tbsp. flour\", \"1 1...   \n\n                                          directions  \\\n0  [\"Blend butter and rosemary in processor.\", \"G...   \n1  [\"Heat olive oil and bacon and cook until baco...   \n2  [\"Mix all ingredients thoroughly.\", \"Bake at 3...   \n3  [\"Prepare 25cm square cake tin by lining with ...   \n4  [\"Scramble sausage in heavy saucepan.\", \"When ...   \n\n                                                link     source  \\\n0  www.food.com/recipe/crisp-rosemary-parmesan-ga...   Gathered   \n1  www.foodnetwork.com/recipes/bean-and-vegetable...  Recipes1M   \n2    www.cookbooks.com/Recipe-Details.aspx?id=678569   Gathered   \n3  www.food.com/recipe/courgette-chocolate-cake-3...   Gathered   \n4    www.cookbooks.com/Recipe-Details.aspx?id=640864   Gathered   \n\n                                                 NER  \n0  [\"butter\", \"fresh rosemary\", \"extra virgin oli...  \n1  [\"extra virgin olive oil\", \"bacon\", \"onions\", ...  \n2  [\"margarine\", \"persimmon\", \"flour\", \"eggs\", \"s...  \n3  [\"butter\", \"brown sugar\", \"white sugar\", \"eggs...  \n4  [\"bulk sausage\", \"flour\", \"milk\", \"salt\", \"ref...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>ingredients</th>\n      <th>directions</th>\n      <th>link</th>\n      <th>source</th>\n      <th>NER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Crisp Rosemary-Parmesan Garlic Bread</td>\n      <td>[\"2 tablespoons butter, room temperature\", \"2 ...</td>\n      <td>[\"Blend butter and rosemary in processor.\", \"G...</td>\n      <td>www.food.com/recipe/crisp-rosemary-parmesan-ga...</td>\n      <td>Gathered</td>\n      <td>[\"butter\", \"fresh rosemary\", \"extra virgin oli...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bean and Vegetable Soup, First Time Around</td>\n      <td>[\"1/4 cup extra virgin olive oil\", \"4 slices b...</td>\n      <td>[\"Heat olive oil and bacon and cook until baco...</td>\n      <td>www.foodnetwork.com/recipes/bean-and-vegetable...</td>\n      <td>Recipes1M</td>\n      <td>[\"extra virgin olive oil\", \"bacon\", \"onions\", ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Persimmon Pudding</td>\n      <td>[\"1 stick margarine\", \"2 c. persimmon\", \"2 c. ...</td>\n      <td>[\"Mix all ingredients thoroughly.\", \"Bake at 3...</td>\n      <td>www.cookbooks.com/Recipe-Details.aspx?id=678569</td>\n      <td>Gathered</td>\n      <td>[\"margarine\", \"persimmon\", \"flour\", \"eggs\", \"s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Courgette Chocolate Cake</td>\n      <td>[\"125 g butter\", \"1 cup brown sugar\", \"1/2 cup...</td>\n      <td>[\"Prepare 25cm square cake tin by lining with ...</td>\n      <td>www.food.com/recipe/courgette-chocolate-cake-3...</td>\n      <td>Gathered</td>\n      <td>[\"butter\", \"brown sugar\", \"white sugar\", \"eggs...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sausage Gravy</td>\n      <td>[\"1/2 lb. bulk sausage\", \"2 Tbsp. flour\", \"1 1...</td>\n      <td>[\"Scramble sausage in heavy saucepan.\", \"When ...</td>\n      <td>www.cookbooks.com/Recipe-Details.aspx?id=640864</td>\n      <td>Gathered</td>\n      <td>[\"bulk sausage\", \"flour\", \"milk\", \"salt\", \"ref...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "recipes_shuffled = recipes.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Select 50% of the recipes randomly\n",
    "num_recipes_to_keep = n_recipes #int(len(recipes_shuffled) * 0.5)\n",
    "recipes = recipes_shuffled[:num_recipes_to_keep]\n",
    "\n",
    "# Print the new DataFrame\n",
    "recipes.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:43:15.359790Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        100 non-null    object\n",
      " 1   ingredients  100 non-null    object\n",
      " 2   directions   100 non-null    object\n",
      " 3   link         100 non-null    object\n",
      " 4   source       100 non-null    object\n",
      " 5   NER          100 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(recipes.info())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:43:17.853540Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tokenize, compute TF-IDF and prepare the similarity measure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_path, padding_side='left')\n",
    "    return model, tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:43:23.925254Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def prepare_similarity_matrix(recipes):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(recipes['NER'])\n",
    "    return tfidf_vectorizer, tfidf_matrix\n",
    "\n",
    "tfidf_vectorizer, tfidf_matrix = prepare_similarity_matrix(recipes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:43:25.635225Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def find_best_match(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix):\n",
    "    \"\"\"Calculate cosine similarity and return the best recipe match.\"\"\"\n",
    "    user_input_tfidf = tfidf_vectorizer.transform([' '.join(user_ingredients)])\n",
    "    cos_similarities = cosine_similarity(user_input_tfidf, tfidf_matrix)\n",
    "    best_recipe_index = cos_similarities.argmax()\n",
    "    return recipes.iloc[best_recipe_index]\n",
    "\n",
    "def remove_repetitions(text):\n",
    "    \"\"\"Helper function to remove repeated sentences in a list of directions.\"\"\"\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for item in text:\n",
    "        if item not in seen:\n",
    "            seen.add(item)\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "def generate_recipe_text(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix, model, tokenizer):\n",
    "    # Find the recipe that matches the user ingredients\n",
    "    best_recipe = find_best_match(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix)\n",
    "\n",
    "    # Parse ingredients and directions from the dataframe\n",
    "    ingredients_list = ast.literal_eval(best_recipe['ingredients'])\n",
    "    directions_list = ast.literal_eval(best_recipe['directions'])\n",
    "\n",
    "    # Reformat input to the model\n",
    "    ingredients_text = \"Ingredients:\\n\" + \"\\n\".join([f\"- {ingredient}\" for ingredient in ingredients_list])\n",
    "    directions_text = \"Directions:\\n\" + \"\\n\".join([f\"Step {i+1}: {step}\" for i, step in enumerate(directions_list)])\n",
    "    prompt_text = f\"Recipe Title: {best_recipe['title']}\\n\\n{ingredients_text}\\n\\n{directions_text}\"\n",
    "\n",
    "    # Generate the recipe text\n",
    "    encoded = tokenizer.encode_plus(prompt_text, return_tensors=\"pt\", padding='max_length', truncation=True)\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask, pad_token_id=pad_token_id, max_length=1024 + 50, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Remove repetitions in the generated text\n",
    "    final_text_lines = generated_text.split('\\n')\n",
    "    final_text_lines = remove_repetitions(final_text_lines)\n",
    "\n",
    "    return \"\\n\".join(final_text_lines)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:43:28.108091Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Prepare data for training the GPT-2 model.\n",
    "- DataLoader creation for training and validation sets.\n",
    "- Model Training & Validation methods"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoded['input_ids'].flatten(),\n",
    "            'attention_mask': encoded['attention_mask'].flatten(),\n",
    "            'labels': encoded['input_ids'].flatten()  # Labels for language modeling\n",
    "        }\n",
    "\n",
    "\n",
    "def create_data_loaders(recipes, batch_size, tokenizer, max_length):\n",
    "    # Combine title, ingredients, and directions into a single text input for each recipe\n",
    "    combined_texts = recipes.apply(lambda row: f\"Recipe Title: {row['title']} Ingredients: {row['ingredients']} Directions: {row['directions']}\", axis=1)\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    train_texts, val_texts = train_test_split(combined_texts, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create Dataset objects\n",
    "    train_dataset = RecipeDataset(train_texts.tolist(), tokenizer, max_length)\n",
    "    val_dataset = RecipeDataset(val_texts.tolist(), tokenizer, max_length)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:43:31.659654Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def train_and_validate(model, device, train_loader, val_loader, best_params=None):\n",
    "    print(\"Training optimized model...\")\n",
    "\n",
    "    if best_params is None:\n",
    "        best_params = {}\n",
    "    \n",
    "    num_train_epochs = int(best_params.get('num_train_epochs', 10))\n",
    "    learning_rate = best_params.get('learning_rate', 1e-5)\n",
    "    weight_decay = best_params.get('weight_decay', 0)  # Default 0 if not specified\n",
    "    warmup_steps = int(best_params.get('warmup_steps', 0))  # Default 0 if not specified\n",
    "\n",
    "    # Set up the optimizer and scheduler using the best learning rate\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    total_steps = len(train_loader) * num_train_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "    \n",
    "    # Use gradient accumulation to handle memory limits\n",
    "    accumulation_steps = 4  # Adjust based on specific memory constraints\n",
    "\n",
    "\n",
    "    # Lists to store per-epoch metrics\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    training_perplexities = []\n",
    "    validation_perplexities = []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_train_epochs):\n",
    "        total_loss = 0\n",
    "        model.zero_grad()\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / accumulation_steps  # Normalize the loss to account for accumulation\n",
    "            \n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if (step + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            # scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_ppl = torch.exp(torch.tensor(avg_train_loss)).item()\n",
    "        training_losses.append(avg_train_loss)\n",
    "        training_perplexities.append(train_ppl)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_ppl = torch.exp(torch.tensor(avg_val_loss)).item()\n",
    "        validation_losses.append(avg_val_loss)\n",
    "        validation_perplexities.append(val_ppl)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_train_epochs} | Train Loss: {avg_train_loss:.3f} | Train PPL: {train_ppl:.3f} | Val Loss: {avg_val_loss:.3f} | Val PPL: {val_ppl:.3f}\")\n",
    "        \n",
    "        # Save the best model if validation loss improved\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            print(f\"Saved new best model at {best_model_path}\")\n",
    "            \n",
    "        # Clear memory at the end of each epoch\n",
    "        clear_memory()\n",
    "    \n",
    "    print(f\"Saved new best model at {best_model_path}\")\n",
    "    \n",
    "    return training_losses, validation_losses, training_perplexities, validation_perplexities, model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T09:57:18.104351Z",
     "start_time": "2024-04-28T09:57:18.082633Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_validation_curves(training_losses, validation_losses, training_perplexities, validation_perplexities):\n",
    "    epochs = range(1, len(training_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, training_losses, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, validation_losses, 'ro-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, training_perplexities, 'bo-', label='Training Perplexity')\n",
    "    plt.plot(epochs, validation_perplexities, 'ro-', label='Validation Perplexity')\n",
    "    plt.title('Training and Validation Perplexity')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Perplexity')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T09:57:20.241024Z",
     "start_time": "2024-04-28T09:57:20.235701Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model optimization with Bayesian Optimization: \n",
    "This approach combines traditional NLP techniques for ingredient matching with advanced language generation capabilities of GPT-2\n",
    "\n",
    "- Prepare data for fine-tuning: tokenize and format the data suitable for GPT-2\n",
    "- Hyperparameter Tuning: Explore different learning rates, batch sizes, and number of epochs\n",
    "    - Bayesian Optimization uses a probabilistic model to guide the search for the best hyperparameters. It balances exploration and exploitation to find the optimal hyperparameters efficiently. \n",
    "\n",
    "- Training: Train the model with recipes data, monitoring for convergence and performance.\n",
    "- Evaluation: Evaluate the model using validation data and metrics like perplexity.\n",
    "- Visualization of Results: Use plots to show training losses and evaluation metrics."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Optimizer Selection\n",
    "- Adam is a popular choice due to its effectiveness in handling sparse gradients and adaptive learning rate techniques.\n",
    "\n",
    "Learning Rates\n",
    "- Initial Value: Starting learning rate in the range of 2e-5 to 5e-5, which are common starting points for fine-tuning language models.\n",
    "- Decay Strategy: Reduce the learning rate gradually as training progresses. This helps in fine-tuning the model to achieve better performance as it converges.\n",
    "- Warm-up Steps: Implementing a warm-up period for the learning rate can help stabilize the model's training early in the process, gradually increasing the learning rate from zero to the initial set learning rate.\n",
    "\n",
    "Batch Sizes\n",
    "- Size Range: Experiment with batch sizes, starting from smaller batches like 4 or 8, up to larger batches if your hardware supports it (e.g., 16, 32). Larger batch sizes provide a more stable gradient, but they require more memory.\n",
    "- Gradient Accumulation: If memory limits batch size, used to simulate larger batches. This means updating model weights less frequently, accumulating gradients over multiple forward passes.\n",
    "\n",
    "Number of Epochs\n",
    "- Epoch Count: Number of epochs is increased based on the initial results and if the model has not started overfitting. (See how quickly the model learns)\n",
    "- Early Stopping: Halt training when the validation metric (like perplexity or validation loss) stops improving. This prevents overfitting and saves computational resources.\n",
    "\n",
    "Weight Decay \n",
    "- (L2 Regularization): Prevents overfitting by penalizing large weights. Helps maintain a balance between model complexity and dataset simplicity.\n",
    "\n",
    "Gradient Clipping: \n",
    "- Prevents exploding gradients. By setting a threshold for gradient clipping, we ensure that gradients exceeding this threshold are scaled down to maintain stability in the training process.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def tune_model(learning_rate, weight_decay, num_train_epochs, warmup_steps, batch_size):\n",
    "    batch_size = int(batch_size)\n",
    "    num_train_epochs = int(num_train_epochs)\n",
    "    warmup_steps = int(warmup_steps)\n",
    "    \n",
    "    train_loader, val_loader = create_data_loaders(recipes, batch_size, tokenizer, max_length=512)\n",
    "    \n",
    "    # Set up optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    total_steps = len(train_loader) * num_train_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "\n",
    "    # Define gradient accumulation steps to handle memory limits\n",
    "    accumulation_steps = 4  # Adjust based on your specific memory constraints\n",
    "    patience_limit = 3  # Early stopping after 3 epochs with no improvement\n",
    "    min_val_loss = float('inf')\n",
    "    gradient_clipping_norm = 1.0  # Common value for clipping gradients\n",
    "    patience = 0\n",
    "        \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_train_epochs):\n",
    "        total_loss = 0\n",
    "        model.zero_grad()\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / accumulation_steps  # Normalize the loss to account for accumulation\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if (step + 1) % accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping_norm)\n",
    "                \n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if avg_val_loss < min_val_loss:\n",
    "            min_val_loss = avg_val_loss\n",
    "            patience = 0\n",
    "            \n",
    "            # Save the best model\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= patience_limit:\n",
    "                print(f\"Stopping early at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.3f}, Val Loss: {avg_val_loss:.3f}\")\n",
    "        \n",
    "        # Clear memory at the end of each epoch\n",
    "        clear_memory()\n",
    "    \n",
    "    # print(f\"Best model saved at {best_model_path}\")\n",
    "\n",
    "    return -min_val_loss  # Maximizing the negative loss in Bayesian optimization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:50:22.401620Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = load_model(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:50:23.641960Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... | num_tr... | warmup... | weight... |\n",
      "-------------------------------------------------------------------------------------\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 3.976, Val Loss: 22.049\n",
      "| \u001B[0m1        \u001B[0m | \u001B[0m-22.05   \u001B[0m | \u001B[0m55.71    \u001B[0m | \u001B[0m7.231e-05\u001B[0m | \u001B[0m1.001    \u001B[0m | \u001B[0m3.023e+03\u001B[0m | \u001B[0m0.001553 \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 1.735, Val Loss: 6.846\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 2: Train Loss: 1.668, Val Loss: 6.846\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 3: Train Loss: 1.677, Val Loss: 6.845\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 4: Train Loss: 1.670, Val Loss: 6.843\n",
      "| \u001B[95m2        \u001B[0m | \u001B[95m-6.843   \u001B[0m | \u001B[95m15.45    \u001B[0m | \u001B[95m1.944e-05\u001B[0m | \u001B[95m4.11     \u001B[0m | \u001B[95m3.968e+03\u001B[0m | \u001B[95m0.005434 \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 1.780, Val Loss: 6.810\n",
      "Epoch 2: Train Loss: 1.677, Val Loss: 6.810\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 3: Train Loss: 1.677, Val Loss: 6.808\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 4: Train Loss: 1.678, Val Loss: 6.803\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 5: Train Loss: 1.662, Val Loss: 6.795\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 6: Train Loss: 1.676, Val Loss: 6.786\n",
      "| \u001B[95m3        \u001B[0m | \u001B[95m-6.786   \u001B[0m | \u001B[95m12.08    \u001B[0m | \u001B[95m5.59e-05 \u001B[0m | \u001B[95m6.184    \u001B[0m | \u001B[95m3.965e+03\u001B[0m | \u001B[95m0.003784 \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 1.720, Val Loss: 6.728\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 2: Train Loss: 1.658, Val Loss: 6.641\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 3: Train Loss: 1.634, Val Loss: 6.492\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 4: Train Loss: 1.592, Val Loss: 6.248\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 5: Train Loss: 1.534, Val Loss: 6.023\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 6: Train Loss: 1.482, Val Loss: 5.730\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 7: Train Loss: 1.404, Val Loss: 5.327\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 8: Train Loss: 1.305, Val Loss: 4.875\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 9: Train Loss: 1.210, Val Loss: 4.397\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 10: Train Loss: 1.096, Val Loss: 3.894\n",
      "| \u001B[95m4        \u001B[0m | \u001B[95m-3.894   \u001B[0m | \u001B[95m4.0      \u001B[0m | \u001B[95m8.076e-05\u001B[0m | \u001B[95m10.0     \u001B[0m | \u001B[95m4.909e+03\u001B[0m | \u001B[95m0.009561 \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 1.271, Val Loss: 3.893\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 2: Train Loss: 1.030, Val Loss: 3.890\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 3: Train Loss: 1.029, Val Loss: 3.887\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 4: Train Loss: 1.028, Val Loss: 3.877\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 5: Train Loss: 1.025, Val Loss: 3.867\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 6: Train Loss: 1.023, Val Loss: 3.853\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 7: Train Loss: 1.019, Val Loss: 3.834\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 8: Train Loss: 1.015, Val Loss: 3.811\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 9: Train Loss: 1.010, Val Loss: 3.786\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 10: Train Loss: 1.004, Val Loss: 3.759\n",
      "| \u001B[95m5        \u001B[0m | \u001B[95m-3.759   \u001B[0m | \u001B[95m4.0      \u001B[0m | \u001B[95m9.612e-06\u001B[0m | \u001B[95m10.0     \u001B[0m | \u001B[95m5.542e+03\u001B[0m | \u001B[95m0.01     \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 9.840, Val Loss: 23.044\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 2: Train Loss: 0.006, Val Loss: 23.043\n",
      "Epoch 3: Train Loss: 0.000, Val Loss: 23.043\n",
      "Epoch 4: Train Loss: 10.332, Val Loss: 23.044\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 5: Train Loss: 10.311, Val Loss: 23.043\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 6: Train Loss: 0.003, Val Loss: 23.043\n",
      "Epoch 7: Train Loss: 0.035, Val Loss: 23.044\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 8: Train Loss: 0.013, Val Loss: 23.043\n",
      "Epoch 9: Train Loss: 10.334, Val Loss: 23.043\n",
      "Epoch 10: Train Loss: 0.000, Val Loss: 23.044\n",
      "| \u001B[0m6        \u001B[0m | \u001B[0m-23.04   \u001B[0m | \u001B[0m128.0    \u001B[0m | \u001B[0m3.699e-05\u001B[0m | \u001B[0m10.0     \u001B[0m | \u001B[0m6.358e+03\u001B[0m | \u001B[0m0.01     \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 1.405, Val Loss: 4.982\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 2: Train Loss: 1.327, Val Loss: 4.972\n",
      "| \u001B[0m7        \u001B[0m | \u001B[0m-4.972   \u001B[0m | \u001B[0m6.928    \u001B[0m | \u001B[0m6.348e-05\u001B[0m | \u001B[0m2.7      \u001B[0m | \u001B[0m9.997e+03\u001B[0m | \u001B[0m0.001524 \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 9.779, Val Loss: 23.047\n",
      "Epoch 2: Train Loss: 10.322, Val Loss: 23.048\n",
      "Epoch 3: Train Loss: 10.321, Val Loss: 23.049\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 4: Train Loss: 0.000, Val Loss: 23.047\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 5: Train Loss: 0.003, Val Loss: 23.046\n",
      "Epoch 6: Train Loss: 0.000, Val Loss: 23.048\n",
      "Epoch 7: Train Loss: 10.324, Val Loss: 23.047\n",
      "Stopping early at epoch 8\n",
      "| \u001B[0m8        \u001B[0m | \u001B[0m-23.05   \u001B[0m | \u001B[0m128.0    \u001B[0m | \u001B[0m9.434e-05\u001B[0m | \u001B[0m10.0     \u001B[0m | \u001B[0m9.32e+03 \u001B[0m | \u001B[0m0.0001   \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 0.023, Val Loss: 23.047\n",
      "Epoch 2: Train Loss: 0.000, Val Loss: 23.048\n",
      "Epoch 3: Train Loss: 0.037, Val Loss: 23.047\n",
      "Stopping early at epoch 4\n",
      "| \u001B[0m9        \u001B[0m | \u001B[0m-23.05   \u001B[0m | \u001B[0m124.7    \u001B[0m | \u001B[0m7.825e-05\u001B[0m | \u001B[0m7.059    \u001B[0m | \u001B[0m5.229e+03\u001B[0m | \u001B[0m0.002804 \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 1.248, Val Loss: 3.747\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 2: Train Loss: 0.996, Val Loss: 3.725\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 3: Train Loss: 0.989, Val Loss: 3.684\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 4: Train Loss: 0.978, Val Loss: 3.620\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 5: Train Loss: 0.963, Val Loss: 3.557\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 6: Train Loss: 0.952, Val Loss: 3.510\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 7: Train Loss: 0.941, Val Loss: 3.473\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 8: Train Loss: 0.935, Val Loss: 3.454\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 9: Train Loss: 0.930, Val Loss: 3.430\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 10: Train Loss: 0.925, Val Loss: 3.390\n",
      "| \u001B[95m10       \u001B[0m | \u001B[95m-3.39    \u001B[0m | \u001B[95m4.0      \u001B[0m | \u001B[95m5.092e-05\u001B[0m | \u001B[95m10.0     \u001B[0m | \u001B[95m5.727e+03\u001B[0m | \u001B[95m0.01     \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 1.198, Val Loss: 3.385\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 2: Train Loss: 0.916, Val Loss: 3.379\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 3: Train Loss: 0.914, Val Loss: 3.358\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 4: Train Loss: 0.907, Val Loss: 3.319\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 5: Train Loss: 0.897, Val Loss: 3.263\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 6: Train Loss: 0.882, Val Loss: 3.195\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 7: Train Loss: 0.866, Val Loss: 3.124\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 8: Train Loss: 0.850, Val Loss: 3.060\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 9: Train Loss: 0.835, Val Loss: 2.995\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 10: Train Loss: 0.821, Val Loss: 2.936\n",
      "| \u001B[95m11       \u001B[0m | \u001B[95m-2.936   \u001B[0m | \u001B[95m4.0      \u001B[0m | \u001B[95m2.742e-05\u001B[0m | \u001B[95m10.0     \u001B[0m | \u001B[95m4.67e+03 \u001B[0m | \u001B[95m0.01     \u001B[0m |\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 1: Train Loss: 1.086, Val Loss: 2.936\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 2: Train Loss: 0.812, Val Loss: 2.933\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 3: Train Loss: 0.811, Val Loss: 2.924\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 4: Train Loss: 0.808, Val Loss: 2.911\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 5: Train Loss: 0.804, Val Loss: 2.895\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 6: Train Loss: 0.800, Val Loss: 2.874\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 7: Train Loss: 0.795, Val Loss: 2.857\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 8: Train Loss: 0.792, Val Loss: 2.847\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 9: Train Loss: 0.789, Val Loss: 2.834\n",
      "Best model saved at ./models/best_gpt2_model_100\n",
      "Epoch 10: Train Loss: 0.785, Val Loss: 2.810\n",
      "| \u001B[95m12       \u001B[0m | \u001B[95m-2.81    \u001B[0m | \u001B[95m4.0      \u001B[0m | \u001B[95m1.304e-05\u001B[0m | \u001B[95m10.0     \u001B[0m | \u001B[95m4.364e+03\u001B[0m | \u001B[95m0.0001   \u001B[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define parameter bounds\n",
    "pbounds = {\n",
    "    'learning_rate': (1e-6, 1e-4),\n",
    "    'batch_size': (4, 128),\n",
    "    'num_train_epochs': (1, 10),\n",
    "    'weight_decay': (1e-4, 1e-2),\n",
    "    'warmup_steps': (0, 10000),\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=tune_model,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=10,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T05:50:37.810823Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Recipes used: 100\n",
      "Best model in: ./models/best_gpt2_model_100\n",
      "\n",
      "Best hyperparameters found:\n",
      "- Learning Rate: 1.3041e-05\n",
      "- Batch Size: 4\n",
      "- Training Epochs: 10\n",
      "- Weight Decay: 1.0000e-04\n",
      "- Warmup Steps: 4364\n"
     ]
    }
   ],
   "source": [
    "print(f\"# Recipes used: {n_recipes}\")\n",
    "print(f\"Best model in: {best_model_path}\")\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(\"\\nBest hyperparameters found:\")\n",
    "print(f\"- Learning Rate: {best_params['learning_rate']:.4e}\")\n",
    "print(f\"- Batch Size: {int(best_params['batch_size'])}\")\n",
    "print(f\"- Training Epochs: {int(best_params['num_train_epochs'])}\")\n",
    "print(f\"- Weight Decay: {best_params['weight_decay']:.4e}\")\n",
    "print(f\"- Warmup Steps: {int(best_params['warmup_steps'])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T08:32:12.220993Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved as P2R_NPL_GPT2_100_checkpoint_20240428_044231.ipynb\n"
     ]
    }
   ],
   "source": [
    "# sys.path.insert(0, './utils/common.py')\n",
    "# from utils.common import save_checkpoint, load_checkpoint\n",
    "\n",
    "# Save the notebook\n",
    "checkpoint_name = save_checkpoint('P2R_NPL_GPT2_100.ipynb')\n",
    "\n",
    "# Load the checkpoint\n",
    "# nb = load_checkpoint(f'{checkpoint_name}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T08:42:31.176808Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Optimized Model Training and Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: './models/best_gpt2_model_100'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHFValidationError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/utils/hub.py:385\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    384\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 385\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m GatedRepoError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:110\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arg_name \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrepo_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 110\u001B[0m     \u001B[43mvalidate_repo_id\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m arg_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m arg_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:158\u001B[0m, in \u001B[0;36mvalidate_repo_id\u001B[0;34m(repo_id)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repo_id\u001B[38;5;241m.\u001B[39mcount(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HFValidationError(\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepo id must be in the form \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrepo_name\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnamespace/repo_name\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Use `repo_type` argument if needed.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    161\u001B[0m     )\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m REPO_ID_REGEX\u001B[38;5;241m.\u001B[39mmatch(repo_id):\n",
      "\u001B[0;31mHFValidationError\u001B[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models/best_gpt2_model_100'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[43], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m best_model, tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbest_model_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m best_model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model_path)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(model_path):\n\u001B[0;32m----> 2\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mGPT2LMHeadModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m GPT2Tokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_path, padding_side\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model, tokenizer\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/modeling_utils.py:2926\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   2923\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m commit_hash \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2924\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PretrainedConfig):\n\u001B[1;32m   2925\u001B[0m         \u001B[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001B[39;00m\n\u001B[0;32m-> 2926\u001B[0m         resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2927\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2928\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2929\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2930\u001B[0m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2931\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2932\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2933\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2934\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2935\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2936\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2937\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_missing_entries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2938\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_connection_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2939\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2940\u001B[0m         commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001B[1;32m   2941\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/utils/hub.py:450\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    448\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere was a specific connection error when trying to load \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00merr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HFValidationError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 450\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    451\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncorrect path_or_model_id: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    452\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resolved_file\n",
      "\u001B[0;31mOSError\u001B[0m: Incorrect path_or_model_id: './models/best_gpt2_model_100'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "# best_model, tokenizer = load_model(best_model_path)\n",
    "# best_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T08:49:28.732399Z",
     "start_time": "2024-04-28T08:49:27.587038Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training optimized model...\n",
      "Epoch 1/10 | Train Loss: 1.086 | Train PPL: 2.962 | Val Loss: 2.811 | Val PPL: 16.629\n",
      "Saved new best model at ./models/best_gpt2_model_100\n",
      "Epoch 2/10 | Train Loss: 0.781 | Train PPL: 2.184 | Val Loss: 2.812 | Val PPL: 16.648\n",
      "Epoch 3/10 | Train Loss: 0.782 | Train PPL: 2.185 | Val Loss: 2.813 | Val PPL: 16.665\n",
      "Epoch 4/10 | Train Loss: 0.782 | Train PPL: 2.185 | Val Loss: 2.814 | Val PPL: 16.676\n",
      "Epoch 5/10 | Train Loss: 0.782 | Train PPL: 2.186 | Val Loss: 2.816 | Val PPL: 16.713\n",
      "Epoch 6/10 | Train Loss: 0.783 | Train PPL: 2.187 | Val Loss: 2.819 | Val PPL: 16.760\n",
      "Epoch 7/10 | Train Loss: 0.783 | Train PPL: 2.189 | Val Loss: 2.821 | Val PPL: 16.794\n",
      "Epoch 8/10 | Train Loss: 0.784 | Train PPL: 2.190 | Val Loss: 2.828 | Val PPL: 16.911\n",
      "Epoch 9/10 | Train Loss: 0.786 | Train PPL: 2.194 | Val Loss: 2.834 | Val PPL: 17.015\n",
      "Epoch 10/10 | Train Loss: 0.787 | Train PPL: 2.197 | Val Loss: 2.838 | Val PPL: 17.089\n",
      "Saved new best model at ./models/best_gpt2_model_100\n"
     ]
    }
   ],
   "source": [
    "# best_batch_size = int(best_params['batch_size'])\n",
    "# train_loader, val_loader = create_data_loaders(recipes, best_batch_size, tokenizer, max_length=512)\n",
    "\n",
    "# Create data loaders with the best batch size\n",
    "batch_size = int(best_params['batch_size'])\n",
    "train_loader_opt, val_loader_opt = create_data_loaders(recipes, batch_size, tokenizer, max_length=512)\n",
    "    \n",
    "training_losses, validation_losses, training_perplexities, validation_perplexities, model_optim = train_and_validate(model, device, train_loader_opt, val_loader_opt, best_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T10:14:49.893691Z",
     "start_time": "2024-04-28T10:11:47.921422Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# print(model_optim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T10:17:18.514999Z",
     "start_time": "2024-04-28T10:17:18.495813Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing Results\n",
    "\n",
    "- Training Loss: Plot the training and validation loss over epochs to visualize learning progress and diagnose issues like overfitting or underfitting.\n",
    "- BLEU Scores or Perplexity Over Time: Similarly, track and plot BLEU scores or perplexity over epochs to assess language model performance improvements."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_validation_curves(training_losses, validation_losses, training_perplexities, validation_perplexities)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T10:17:40.879502Z",
     "start_time": "2024-04-28T10:17:40.741151Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example: Generating a Recipe with Optimized model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: './models/best_gpt2_model_100'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHFValidationError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/utils/hub.py:385\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    384\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 385\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m GatedRepoError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:110\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m arg_name \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrepo_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_id\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto_id\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m--> 110\u001B[0m     \u001B[43mvalidate_repo_id\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m arg_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m arg_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:158\u001B[0m, in \u001B[0;36mvalidate_repo_id\u001B[0;34m(repo_id)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repo_id\u001B[38;5;241m.\u001B[39mcount(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HFValidationError(\n\u001B[1;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRepo id must be in the form \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrepo_name\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnamespace/repo_name\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    160\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Use `repo_type` argument if needed.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    161\u001B[0m     )\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m REPO_ID_REGEX\u001B[38;5;241m.\u001B[39mmatch(repo_id):\n",
      "\u001B[0;31mHFValidationError\u001B[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models/best_gpt2_model_100'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Load the best model\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m best_model, tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbest_model_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39mpad_token \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39meos_token\n\u001B[1;32m      4\u001B[0m best_model\u001B[38;5;241m.\u001B[39mto(device)\n",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model_path)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(model_path):\n\u001B[0;32m----> 2\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mGPT2LMHeadModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m GPT2Tokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_path, padding_side\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model, tokenizer\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/modeling_utils.py:2926\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   2923\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m commit_hash \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2924\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(config, PretrainedConfig):\n\u001B[1;32m   2925\u001B[0m         \u001B[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001B[39;00m\n\u001B[0;32m-> 2926\u001B[0m         resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2927\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2928\u001B[0m \u001B[43m            \u001B[49m\u001B[43mCONFIG_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2929\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2930\u001B[0m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2931\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2932\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2933\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2934\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2935\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2936\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2937\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_missing_entries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2938\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_raise_exceptions_for_connection_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2939\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2940\u001B[0m         commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001B[1;32m   2941\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/utils/hub.py:450\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    448\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere was a specific connection error when trying to load \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00merr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m HFValidationError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 450\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    451\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncorrect path_or_model_id: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    452\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resolved_file\n",
      "\u001B[0;31mOSError\u001B[0m: Incorrect path_or_model_id: './models/best_gpt2_model_100'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "# # Load the best model\n",
    "# best_model, tokenizer = load_model(best_model_path)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# best_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T09:38:35.279766Z",
     "start_time": "2024-04-28T09:38:35.188708Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (1024). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "3'th index 1024 of condition tensor does not match the other tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[69], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Generate the recipe\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m recipe_text \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_recipe_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_ingredients\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecipes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtfidf_vectorizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtfidf_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_optim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(recipe_text)\n",
      "Cell \u001B[0;32mIn[16], line 38\u001B[0m, in \u001B[0;36mgenerate_recipe_text\u001B[0;34m(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix, model, tokenizer)\u001B[0m\n\u001B[1;32m     36\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m encoded[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     37\u001B[0m pad_token_id \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mpad_token_id\n\u001B[0;32m---> 38\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_return_sequences\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mno_repeat_ngram_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m generated_text \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Remove repetitions from the directions in the generated text\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/generation/utils.py:1479\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1462\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massisted_decoding(\n\u001B[1;32m   1463\u001B[0m         input_ids,\n\u001B[1;32m   1464\u001B[0m         candidate_generator\u001B[38;5;241m=\u001B[39mcandidate_generator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1475\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1476\u001B[0m     )\n\u001B[1;32m   1477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mGREEDY_SEARCH:\n\u001B[1;32m   1478\u001B[0m     \u001B[38;5;66;03m# 11. run greedy search\u001B[39;00m\n\u001B[0;32m-> 1479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgreedy_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m        \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mCONTRASTIVE_SEARCH:\n\u001B[1;32m   1493\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/generation/utils.py:2340\u001B[0m, in \u001B[0;36mGenerationMixin.greedy_search\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   2337\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m   2339\u001B[0m \u001B[38;5;66;03m# forward pass to get next token\u001B[39;00m\n\u001B[0;32m-> 2340\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2341\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2343\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2344\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2345\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[1;32m   2348\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# don't waste resources running the code we don't need\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:1074\u001B[0m, in \u001B[0;36mGPT2LMHeadModel.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1066\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1067\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1068\u001B[0m \u001B[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001B[39;00m\n\u001B[1;32m   1069\u001B[0m \u001B[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001B[39;00m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1074\u001B[0m transformer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1088\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1089\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m transformer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1091\u001B[0m \u001B[38;5;66;03m# Set device for model parallelism\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:888\u001B[0m, in \u001B[0;36mGPT2Model.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    876\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    877\u001B[0m         block\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    878\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    885\u001B[0m         output_attentions,\n\u001B[1;32m    886\u001B[0m     )\n\u001B[1;32m    887\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 888\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_past\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_past\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    899\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:390\u001B[0m, in \u001B[0;36mGPT2Block.forward\u001B[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    388\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m    389\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_1(hidden_states)\n\u001B[0;32m--> 390\u001B[0m attn_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_past\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_past\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    398\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_outputs[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# output_attn: a, present, (attentions)\u001B[39;00m\n\u001B[1;32m    399\u001B[0m outputs \u001B[38;5;241m=\u001B[39m attn_outputs[\u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:331\u001B[0m, in \u001B[0;36mGPT2Attention.forward\u001B[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    329\u001B[0m     attn_output, attn_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 331\u001B[0m     attn_output, attn_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    333\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_heads(attn_output, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\n\u001B[1;32m    334\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc_proj(attn_output)\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:202\u001B[0m, in \u001B[0;36mGPT2Attention._attn\u001B[0;34m(self, query, key, value, attention_mask, head_mask)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;66;03m# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\u001B[39;00m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;66;03m# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\u001B[39;00m\n\u001B[1;32m    201\u001B[0m     mask_value \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfull([], mask_value, dtype\u001B[38;5;241m=\u001B[39mattn_weights\u001B[38;5;241m.\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mattn_weights\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 202\u001B[0m     attn_weights \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_weights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattn_weights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;66;03m# Apply the attention mask\u001B[39;00m\n\u001B[1;32m    206\u001B[0m     attn_weights \u001B[38;5;241m=\u001B[39m attn_weights \u001B[38;5;241m+\u001B[39m attention_mask\n",
      "\u001B[0;31mRuntimeError\u001B[0m: 3'th index 1024 of condition tensor does not match the other tensors"
     ]
    }
   ],
   "source": [
    "# Generate the recipe\n",
    "recipe_text = generate_recipe_text(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix, model_optim, tokenizer)\n",
    "\n",
    "print(recipe_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T10:18:50.006899Z",
     "start_time": "2024-04-28T10:18:48.415489Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### If best N epochs = 1, then train for 1 epoch to visualize the training process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# Train for 1 epoch to visualize the training process\n",
    "\n",
    "def train_for_one_epoch(model, train_loader, val_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:  # Log every 10 batches\n",
    "            print(f'Batch {batch_idx + 1}, Loss: {loss.item()}')\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    print('Training for 1 Epoch:')\n",
    "    print(f'- Average Training Loss: {avg_train_loss}')\n",
    "    print(f'- Validation Loss: {avg_val_loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T00:50:51.376853Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1 Epoch:\n",
      "- Average Training Loss: 6.456393718719482\n",
      "- Validation Loss: 6.381645679473877\n"
     ]
    }
   ],
   "source": [
    "best_batch_size = int(best_params['batch_size'])\n",
    "train_loader_1E, val_loader_1E = create_data_loaders(recipes, best_batch_size, tokenizer, max_length=512)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model_optim.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
    "train_for_one_epoch(model, train_loader_1E, val_loader_1E, optimizer, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T00:50:52.557360Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/generation/utils.py:1141: UserWarning: Input length of input_ids is 512, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'perplexity': 32.51880950736368, 'bleu': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "# Ensure that NLTK resources are downloaded\n",
    "# nltk.download('punkt')\n",
    "\n",
    "def calculate_bleu(references, hypotheses):\n",
    "    \"\"\"\n",
    "    Calculate BLEU score between actual and predicted sentences.\n",
    "    \"\"\"\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return corpus_bleu([[ref.split()] for ref in references], [hyp.split() for hyp in hypotheses], smoothing_function=smoothie)\n",
    "\n",
    "\n",
    "def evaluate_model(model, tokenizer, device, val_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation set after one epoch of training.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    hypotheses = []\n",
    "    references = []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Generate text from input ids\n",
    "            generated_ids = model.generate(input_ids, attention_mask=attention_mask)\n",
    "            generated_text = [tokenizer.decode(g_id, skip_special_tokens=True) for g_id in generated_ids]\n",
    "            actual_text = [tokenizer.decode(a_id, skip_special_tokens=True) for a_id in labels]\n",
    "            \n",
    "            hypotheses.extend(generated_text)\n",
    "            references.extend(actual_text)\n",
    "\n",
    "    # Calculate Perplexity \n",
    "    perplexity = np.exp(total_loss / len(val_loader))\n",
    "    \n",
    "    # Calculate BLEU score\n",
    "    bleu_score = calculate_bleu(references, hypotheses)\n",
    "    \n",
    "    return {\n",
    "        'perplexity': perplexity,\n",
    "        'bleu': bleu_score,\n",
    "    }\n",
    "\n",
    "\n",
    "results = evaluate_model(best_model, tokenizer, device, val_loader_1E)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T01:02:13.048383Z",
     "start_time": "2024-04-28T01:02:10.118526Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-trained GPT-2 Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the GPT-2 model and tokenizer\n",
    "# model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model, tokenizer = load_model('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T01:04:36.461346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 1.735 | Train PPL: 5.671 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 2/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 3/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 4/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 5/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 6/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 7/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 8/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 9/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 10/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "train_loader, val_loader = create_data_loaders(recipes, batch_size, tokenizer, max_length=512)\n",
    "\n",
    "training_losses, validation_losses, training_perplexities, validation_perplexities, model = train_and_validate(model, device, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T01:05:49.132635Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACDgElEQVR4nOzde3zP9f//8fvbTnZ0zA4ZJipypoQwsYmQVMqZVMpxoYNUphziW1GUDh/hE6JySAcy5ZhklHJKKeSwtZI2jO1te/3+2G/vj7dtzGyv9/v1drteLu8L7+f79X69Ho/34z17eryf79fLZhiGIQAAAAAAAMBEpVwdAAAAAAAAAK4+NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlgAvYbLZC3datW3dFx4mPj5fNZivSc9etW1csMbi7/v37q1q1agU+/tdff8nX11cPPPBAgdukpaUpICBAXbp0KfRx586dK5vNpoMHDxY6lvPZbDbFx8cX+ni5jh07pvj4eO3YsSPPY1fyfrlS1apVU6dOnVxybACAuZgHuQ/mQf/j6nnQ+e/9oKAgNW3aVP/9739dEo90efUoqgvruGfPHsXHxzu9L4Di4O3qAAB38+233zrdf/HFF7V27Vp9/fXXTuO1a9e+ouM89NBDuuOOO4r03EaNGunbb7+94his7pprrlGXLl20fPlynThxQuXKlcuzzaJFi3TmzBkNHDjwio713HPPacSIEVe0j0s5duyYxo8fr2rVqqlBgwZOj13J+wUAgMJiHmQdzIPM06JFC7388suSpCNHjujll19Wv379dPr0aT322GMui6skffvtt6pcubLj/p49ezR+/HhFR0eXeEMMVxeaUsAFbr31Vqf711xzjUqVKpVn/ELp6ekKCAgo9HEqV67s9A/95QgJCblkPFeLgQMHasmSJVqwYIGGDh2a5/H33ntPoaGhuvPOO6/oONddd90VPf9KXcn7BQCAwmIeZC3Mg8xRtmxZp/dcu3btVLVqVb366qtX3JSy2+2y2Wzy9nav/5rzMwaz8PU9oAiio6NVp04dbdiwQc2bN1dAQIAefPBBSdLixYsVGxur8PBw+fv7q1atWnr66ad1+vRpp33ktww592tSq1atUqNGjeTv768bb7xR7733ntN2+S1b79+/v4KCgrR//3517NhRQUFBioyM1KhRo5SRkeH0/CNHjujee+9VcHCwypYtq169eikxMVE2m01z5869aO5//fWXBg8erNq1aysoKEiVKlXS7bffro0bNzptd/DgQdlsNr388st69dVXFRUVpaCgIDVr1kxbtmzJs9+5c+fqhhtukJ+fn2rVqlXoJdHt27dX5cqVNWfOnDyP7d27V99995369u0rb29vJSQk6K677lLlypVVunRp1ahRQ4MGDdLff/99yePkt0w6LS1NDz/8sCpUqKCgoCDdcccd+uWXX/I8d//+/RowYIBq1qypgIAAXXvttercubN27tzp2GbdunW6+eabJUkDBgxwLBHPXTad3/slOztbU6dO1Y033ig/Pz9VqlRJffv21ZEjR5y2y32/JiYmqmXLlgoICFD16tX10ksvKTs7+5K5F8bZs2c1ZswYRUVFydfXV9dee62GDBmif//912m7r7/+WtHR0apQoYL8/f1VpUoV3XPPPUpPT3dsM2vWLNWvX19BQUEKDg7WjTfeqGeeeaZY4gQAXDnmQcyDpKt7HlS2bFndcMMNOnTokGPs119/Vc+ePVWpUiVHHd944w2n5+W+d99//32NGjVK1157rfz8/LR//37H1yYTEhI0YMAAlS9fXoGBgercubN+//33S8ZkGIbefPNNNWjQQP7+/ipXrpzuvfdep+cuWrRINptNM2fOdHruuHHj5OXlpYSEBMfY+a//3Llzdd9990mS2rRp46jP3Llz9eKLL8rb21uHDx/OE9ODDz6oChUq6OzZs5d+UXHVoikFFFFSUpJ69+6tnj176osvvtDgwYMl5fxC6tixo2bPnq1Vq1YpLi5OH374oTp37lyo/f74448aNWqUHn/8cX3yySeqV6+eBg4cqA0bNlzyuXa7XV26dFHbtm31ySef6MEHH9S0adM0ZcoUxzanT59WmzZttHbtWk2ZMkUffvihQkNDdf/99xcqvn/++UdSzi+vzz//XHPmzFH16tUVHR2d77kd3njjDSUkJGj69OlasGCBTp8+rY4dOyo1NdWxzdy5czVgwADVqlVLS5Ys0bPPPqsXX3wxz1cF8lOqVCn1799f33//vX788Uenx3InaLkT5d9++03NmjXTrFmztHr1aj3//PP67rvvdNttt8lutxcq/1yGYahr166OScWyZct06623qkOHDnm2PXbsmCpUqKCXXnpJq1at0htvvCFvb281bdpU+/btk5TzVYTceJ999ll9++23+vbbb/XQQw8VGMNjjz2mp556SjExMVqxYoVefPFFrVq1Ss2bN88zwUxOTlavXr3Uu3dvrVixQh06dNCYMWM0f/78y8r7Yq/Fyy+/rD59+ujzzz/XyJEjNW/ePN1+++2O/wwcPHhQd955p3x9ffXee+9p1apVeumllxQYGKjMzExJOZOlwYMHq3Xr1lq2bJmWL1+uxx9/PM9/ZgAArsU8iHnQ1TwPstvtOnTokK655hpJOV9tu/nmm7Vr1y698sor+uyzz3TnnXdq+PDhGj9+fJ7njxkzRn/88Yfeeustffrpp6pUqZLjsYEDB6pUqVJauHChpk+frq1btyo6OjrPB30XGjRokOLi4tSuXTstX75cb775pnbv3q3mzZvrzz//lCQ98MADevTRRzVq1Cht27ZNUs4HhhMmTNAzzzyjmJiYfPd95513atKkSZJy3tO59bnzzjs1aNAgeXt76+2333Z6zj///KNFixZp4MCBKl26dOFeWFydDAAX1a9fPyMwMNBprHXr1oYk46uvvrroc7Ozsw273W6sX7/ekGT8+OOPjsfGjRtnXPgjWLVqVaN06dLGoUOHHGNnzpwxypcvbwwaNMgxtnbtWkOSsXbtWqc4JRkffvih0z47duxo3HDDDY77b7zxhiHJWLlypdN2gwYNMiQZc+bMuWhOFzp37pxht9uNtm3bGnfffbdj/MCBA4Yko27dusa5c+cc41u3bjUkGR988IFhGIaRlZVlREREGI0aNTKys7Md2x08eNDw8fExqlateskYfv/9d8NmsxnDhw93jNntdiMsLMxo0aJFvs/Jrc2hQ4cMScYnn3zieGzOnDmGJOPAgQOOsX79+jnFsnLlSkOS8dprrzntd+LEiYYkY9y4cQXGe+7cOSMzM9OoWbOm8fjjjzvGExMTC6zBhe+XvXv3GpKMwYMHO2333XffGZKMZ555xjGW+3797rvvnLatXbu20b59+wLjzFW1alXjzjvvLPDxVatWGZKMqVOnOo0vXrzYkGS88847hmEYxscff2xIMnbs2FHgvoYOHWqULVv2kjEBAMzBPOjimAddHfOgjh07Gna73bDb7caBAwcc77cnnnjCMAzDaN++vVG5cmUjNTXV6blDhw41Spcubfzzzz+GYfzvvduqVas8x8l93c9/HxmGYXzzzTeGJGPChAmOsQvr8e233xqSjFdeecXpuYcPHzb8/f2NJ5980jF29uxZo2HDhkZUVJSxZ88eIzQ01GjdurXT+9QwjDx1/Oijj/L83J0fT6VKlYyMjAzH2JQpU4xSpUo5vY+A/LBSCiiicuXK6fbbb88z/vvvv6tnz54KCwuTl5eXfHx81Lp1a0k5y6gvpUGDBqpSpYrjfunSpXX99dc7LQ8uiM1my/NJZL169Zyeu379egUHB+c5WWSPHj0uuf9cb731lho1aqTSpUvL29tbPj4++uqrr/LN784775SXl5dTPJIcMe3bt0/Hjh1Tz549nZZlV61aVc2bNy9UPFFRUWrTpo0WLFjgWHGzcuVKJScnOz4dlKSUlBQ9+uijioyMdMRdtWpVSYWrzfnWrl0rSerVq5fTeM+ePfNse+7cOU2aNEm1a9eWr6+vvL295evrq19//fWyj3vh8fv37+80fsstt6hWrVr66quvnMbDwsJ0yy23OI1d+N4oqtxPci+M5b777lNgYKAjlgYNGsjX11ePPPKI5s2bl+9S9FtuuUX//vuvevTooU8++aRQXykAAJiPeRDzIOnqmQd98cUX8vHxkY+Pj6KiovThhx9q2LBhmjBhgs6ePauvvvpKd999twICAnTu3DnHrWPHjjp79myer2zec889BR7rwte0efPmqlq1qiPn/Hz22Wey2Wzq3bu30/HDwsJUv359p1V8fn5++vDDD3X8+HE1atRIhmHogw8+cHqfXq4RI0YoJSVFH330kaScr1bOmjVLd955JydFxyXRlAKKKDw8PM/YqVOn1LJlS3333XeaMGGC1q1bp8TERC1dulSSdObMmUvut0KFCnnG/Pz8CvXcgICAPMtj/fz8nL7Hffz4cYWGhuZ5bn5j+ck9oWPTpk21ZMkSbdmyRYmJibrjjjvyjfHCfPz8/CT977U4fvy4pJzJwoXyGyvIwIEDdfz4ca1YsUJSzpL1oKAgde/eXVLOL8fY2FgtXbpUTz75pL766itt3brVMUkozOt7vuPHj8vb2ztPfvnFPHLkSD333HPq2rWrPv30U3333XdKTExU/fr1L/u45x9fyv99GBER4Xg815W8rwoTi7e3t2MJey6bzaawsDBHLNddd53WrFmjSpUqaciQIbruuut03XXX6bXXXnM8p0+fPnrvvfd06NAh3XPPPapUqZKaNm3qdI4DAIDrMQ9iHnQ1zYNuu+02JSYmatu2bdqzZ4/+/fdfvf766/L19dXx48d17tw5zZgxw9G4yr117NhRkvJ8yJZf3LkKei9cmNP5/vzzTxmGodDQ0DwxbNmyJc/xa9SooZYtW+rs2bPq1avXReMpjIYNG6ply5aOc2h99tlnOnjwYL4n3wcu5F6n+Acs5MKTLUo5K0aOHTumdevWOT4VlHTJ74CbqUKFCtq6dWue8eTk5EI9f/78+YqOjtasWbOcxk+ePFnkeAo6fmFjkqRu3bqpXLlyeu+999S6dWt99tln6tu3r4KCgiRJu3bt0o8//qi5c+eqX79+juft37+/yHGfO3dOx48fd5ro5Bfz/Pnz1bdvX8d38XP9/fffKlu2bJGPL+Wc0+PCq9EcO3ZMFStWLNJ+ixrLuXPn9Ndffzk1pgzDUHJysuPEpZLUsmVLtWzZUllZWdq2bZtmzJihuLg4hYaG6oEHHpCUc4LTAQMG6PTp09qwYYPGjRunTp066ZdffnF8ogsAcC3mQcyDrqZ5UJkyZdSkSZN8HytXrpy8vLzUp08fDRkyJN9toqKinO7n9/OTq6D3Qo0aNQp8TsWKFWWz2bRx40ZH4/N8F4795z//0eeff65bbrlFM2fO1P3336+mTZsWuP/CGD58uO677z59//33mjlzpq6//voCz1EFnI+VUkAxyv0Fc+E//Bee+M+VWrdurZMnT2rlypVO44sWLSrU8202W578fvrpJ3377bdFiueGG25QeHi4PvjgAxmG4Rg/dOiQNm/eXOj9lC5dWj179tTq1as1ZcoU2e12pyXrxV2bNm3aSJIWLFjgNL5w4cI82+b3mn3++ec6evSo09iFn55eTO5XJi48QWdiYqL27t2rtm3bXnIfxSX3WBfGsmTJEp0+fTrfWLy8vNS0aVPHJ2rff/99nm0CAwPVoUMHjR07VpmZmdq9e3cJRA8AKC7Mgy4f86D/seo8KCAgQG3atNEPP/ygevXqqUmTJnlu+a3UKsiFr+nmzZt16NAhRUdHF/icTp06yTAMHT16NN/j161b17Htzp07NXz4cPXt21cbN25UvXr1dP/99+vEiRMXjetS9bn77rtVpUoVjRo1SmvWrNHgwYMv2nwDcrFSCihGzZs3V7ly5fToo49q3Lhx8vHx0YIFC/JcDcWV+vXrp2nTpql3796aMGGCatSooZUrV+rLL7+UlHMVl4vp1KmTXnzxRY0bN06tW7fWvn379MILLygqKkrnzp277HhKlSqlF198UQ899JDuvvtuPfzww/r3338VHx9/WcvWpZyl62+88YZeffVV3XjjjU7nYrjxxht13XXX6emnn5ZhGCpfvrw+/fTTIn8tLDY2Vq1atdKTTz6p06dPq0mTJvrmm2/0/vvv59m2U6dOmjt3rm688UbVq1dP27dv1//93//l+WTvuuuuk7+/vxYsWKBatWopKChIERERioiIyLPPG264QY888ohmzJihUqVKqUOHDjp48KCee+45RUZG6vHHHy9SXgVJTk7Wxx9/nGe8WrVqiomJUfv27fXUU08pLS1NLVq00E8//aRx48apYcOG6tOnj6Scc3B8/fXXuvPOO1WlShWdPXvWcZnvdu3aSZIefvhh+fv7q0WLFgoPD1dycrImT56sMmXKOK24AgC4H+ZBzIM8dR50Ka+99ppuu+02tWzZUo899piqVaumkydPav/+/fr0008LdSXFXNu2bdNDDz2k++67T4cPH9bYsWN17bXXOq5wmZ8WLVrokUce0YABA7Rt2za1atVKgYGBSkpK0qZNm1S3bl099thjOn36tLp3766oqCi9+eab8vX11YcffqhGjRppwIABWr58eYHHqFOnjiTpnXfeUXBwsEqXLq2oqChHw83Ly0tDhgzRU089pcDAwDzn+wIKwkopoBhVqFBBn3/+uQICAtS7d289+OCDCgoK0uLFi10dmkNgYKC+/vprRUdH68knn9Q999yjP/74Q2+++aYkXXIZ9dixYzVq1CjNnj1bd955p/7zn//orbfe0m233VbkmAYOHKj//Oc/2rNnj7p166YXXnhBzzzzTL4nUL2Yhg0bqmHDhjIMw+nTQUny8fHRp59+quuvv16DBg1Sjx49lJKSojVr1hQp5lKlSmnFihXq1auXpk6dqq5du2rz5s364osv8mz72muvqXfv3po8ebI6d+6sFStWaOnSpbruuuuctgsICNB7772n48ePKzY2VjfffLPeeeedAmOYNWuWXnrpJX3xxRfq1KmTxo4dq9jYWG3evPmyPpErjO3bt+u+++7Lc5s5c6ZsNpuWL1+ukSNHas6cOerYsaNefvll9enTR19//bXjk7UGDRro3LlzGjdunDp06KA+ffror7/+0ooVKxQbGysp5+t9u3bt0ogRIxQTE6PHH39c119/vTZu3JjnnFUAAPfCPKhomAflcOd50KXUrl1b33//verUqaNnn31WsbGxGjhwoD7++OPLXrU1e/ZsZWZm6oEHHtDw4cPVpEkTrVu3TuXLl7/o895++23NnDlTGzZs0AMPPKA777xTzz//vE6fPu04yfujjz6qP/74Qx999JECAwMlSdWrV9d//vMfffLJJ5o+fXqB+4+KitL06dP1448/Kjo6WjfffLM+/fRTp23uv/9+STnnCC1Tpsxl5Y2rl804f50ogKvWpEmT9Oyzz+qPP/7I88kVAACAJ2MeBFebO3euBgwYoMTExALPX+XuZsyYoeHDh2vXrl266aabXB0OLIKv7wFXoZkzZ0rKWcptt9v19ddf6/XXX1fv3r2ZiAEAAI/GPAgoXj/88IMOHDigF154QXfddRcNKVwWmlLAVSggIEDTpk3TwYMHlZGRoSpVquipp57Ss88+6+rQAAAAShTzIKB43X333UpOTlbLli311ltvuTocWAxf3wMAAAAAAIDpONE5AAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADTWfpE59nZ2Tp27JiCg4Nls9lcHQ4AALAYwzB08uRJRUREqFQpPqs7H/MsAABQVIWdY1m6KXXs2DFFRka6OgwAAGBxhw8f5lLwF2CeBQAArtSl5liWbkoFBwdLykkyJCTExdFYh91u1+rVqxUbGysfHx9Xh4OLoFbWQa2sg1pZS0nXKy0tTZGRkY45Bf6Hedbl498X66BW1kK9rINaWYe7zLEs3ZTKXUoeEhLCZOky2O12BQQEKCQkhH8o3By1sg5qZR3UylrMqhdfT8uLedbl498X66BW1kK9rINaWYe7zLE4eQIAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAwI0cPXpUvXv3VoUKFRQQEKAGDRpo+/btjscNw1B8fLwiIiLk7++v6Oho7d6922kfGRkZGjZsmCpWrKjAwEB16dJFR44cMTsVAACAi6IpBQAA4CZOnDihFi1ayMfHRytXrtSePXv0yiuvqGzZso5tpk6dqldffVUzZ85UYmKiwsLCFBMTo5MnTzq2iYuL07Jly7Ro0SJt2rRJp06dUqdOnZSVleWCrAAAAPLn7eoAAAAAkGPKlCmKjIzUnDlzHGPVqlVz/N0wDE2fPl1jx45Vt27dJEnz5s1TaGioFi5cqEGDBik1NVWzZ8/W+++/r3bt2kmS5s+fr8jISK1Zs0bt27c3NScAAICC0JQCAABwEytWrFD79u113333af369br22ms1ePBgPfzww5KkAwcOKDk5WbGxsY7n+Pn5qXXr1tq8ebMGDRqk7du3y263O20TERGhOnXqaPPmzQU2pTIyMpSRkeG4n5aWJkmy2+2y2+0lka7HyX2deL3cH7WyFuplHdTKOkq6VoXdL00pAAAAN/H7779r1qxZGjlypJ555hlt3bpVw4cPl5+fn/r27avk5GRJUmhoqNPzQkNDdejQIUlScnKyfH19Va5cuTzb5D4/P5MnT9b48ePzjK9evVoBAQFXmtpVJSEhwdUhoJColbVQL+ugVtZRUrVKT08v1HY0pQAAANxEdna2mjRpokmTJkmSGjZsqN27d2vWrFnq27evYzubzeb0PMMw8oxd6FLbjBkzRiNHjnTcT0tLU2RkpGJjYxUSElKUdK46drtdCQkJiomJkY+Pj6vDwUVQK2uhXtZBrayjpGuVu+L6UmhKFSQrS9q4UUpKksLDpZYtJS8vV0d15bKyZFu/Xtdu2CBbYKDUpo3186JW1uKJ9aJW1kGtrMVT63UR4eHhql27ttNYrVq1tGTJEklSWFiYpJzVUOHh4Y5tUlJSHKunwsLClJmZqRMnTjitlkpJSVHz5s0LPLafn5/8/PzyjPv4+BT/ZNUT37NZWbJt3qxrN2yQb2CgvD3l/UqtrMMTayV5Zr2olXVQqyIr9NzBsLDU1FRDkpGamlq8O16yxDAqVzYM6X+3ypVzxq3ME/PyxJwMg7ysxBNzMgzPzMsTczIM8rpCJTaXKKIePXoYt912m9NYXFyc0axZM8MwDCM7O9sICwszpkyZ4ng8IyPDKFOmjPHWW28ZhmEY//77r+Hj42MsXrzYsc2xY8eMUqVKGatWrSp0LMyzLoMn5mQYnpmXJ+ZkGORlJZ6Yk2F4Zl6emJNhuN0ci6bUhZYsMQybzblAUs6YzWbdN6An5uWJORkGeVmJJ+ZkGJ6ZlyfmZBjkVQzcrSm1detWw9vb25g4caLx66+/GgsWLDACAgKM+fPnO7Z56aWXjDJlyhhLly41du7cafTo0cMIDw830tLSHNs8+uijRuXKlY01a9YY33//vXH77bcb9evXN86dO1foWJhnFZIn5mQYnpmXJ+ZkGORlJZ6Yk2F4Zl6emJNhuOUcy2YYhlGsa7RMlJaWpjJlyig1NbV4znWQlSVVqyYdOZL/4zabdO210u7d1lqyl5Ul1a4tHT2a/+NWzMsTc5LIy0p5eWJOkmfm5Yk5SVd3XpUrSwcOFEtexT6XKAafffaZxowZo19//VVRUVEaOXKk4+p7kmQYhsaPH6+3335bJ06cUNOmTfXGG2+oTp06jm3Onj2rJ554QgsXLtSZM2fUtm1bvfnmm4qMjCx0HMyzCuFq/jm0Wl6emJNEXlbKyxNzkjwzL0/MSXLbORZNqfOtW5dzvgoAAODe1q6VoqOveDfu2JRyF8yzAAC4Cpk8xyp1xUfyJElJro4AAAAUBr+zrYeaAQDg/kz+fc3V98533lVsLuqLL6RWrUo2luK0YYPUseOlt7NSXp6Yk0ReVsrLE3OSPDMvT8xJIq/C/s6G+/DEedbV/nNopbw8MSeJvKyUlyfmJHlmXp6Yk+S2cyy+vne+3HMdHD2ac7qvCxXzdyxN44l5eWJOEnlZKS9PzEnyzLw8MSeJvDz4nFLugnlWIXhiTpJn5uWJOUnkZaW8PDEnyTPz8sScJLedY/H1vfN5eUmvvZbzd5vN+bHc+9OnW+uNJ3lmXp6Yk0ReVsrLE3OSPDMvT8xJIi+r5QXPrK0n5iR5Zl6emJNEXlbKyxNzkjwzL0/MSXLfvIrten8uUGKXcV6yxDAqV3a+RGJkpHUv+5jLE/PyxJwMg7ysxBNzMgzPzMsTczIM8rpCJTaX8ADMsy6DJ+ZkGJ6ZlyfmZBjkZSWemJNheGZenpiTYbjdHIuv7xUkK0vauDHnJF/h4VLLltbrhOYnK0vn1q7VjpUr1aBDB3m3aWP9vKiVtXhivaiVdVArazGhXnx9r2DMsy4T/75YB7WyFk+sF7WyDmpVZIWdR3Ci84J4eRXLZRDdjpeXjNatdfT0adVv3dozfqColbV4Yr2olXVQK2vx1HrBM9+znvp+pVbW4Ym1kjyzXtTKOqhVieOcUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwHU0pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYzuVNqaNHj6p3796qUKGCAgIC1KBBA23fvt3VYQEAAAAAAKAEebvy4CdOnFCLFi3Upk0brVy5UpUqVdJvv/2msmXLujIsAAAAAAAAlDCXNqWmTJmiyMhIzZkzxzFWrVo11wUEAAAAAAAAU7j063srVqxQkyZNdN9996lSpUpq2LCh3n33XVeGBAAAAAAAABO4dKXU77//rlmzZmnkyJF65plntHXrVg0fPlx+fn7q27dvnu0zMjKUkZHhuJ+WliZJstvtstvtpsVtdbmvFa+Z+6NW1kGtrINaWUtJ14v3AQAAgOu4tCmVnZ2tJk2aaNKkSZKkhg0bavfu3Zo1a1a+TanJkydr/PjxecZXr16tgICAEo/X0yQkJLg6BBQStbIOamUd1MpaSqpe6enpJbJfAAAAXJpLm1Lh4eGqXbu201itWrW0ZMmSfLcfM2aMRo4c6biflpamyMhIxcbGKiQkpERj9SR2u10JCQmKiYmRj4+Pq8PBRVAr66BW1kGtrKWk65W76hoAAADmc2lTqkWLFtq3b5/T2C+//KKqVavmu72fn5/8/PzyjPv4+PAfiyLgdbMOamUd1Mo6qJW1lFS9eA8AAAC4jktPdP74449ry5YtmjRpkvbv36+FCxfqnXfe0ZAhQ1wZFgAAAAAAAEqYS5tSN998s5YtW6YPPvhAderU0Ysvvqjp06erV69ergwLAAAAAAAAJcylX9+TpE6dOqlTp06uDgMAAAAAAAAmculKKQAAAAAAAFydaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwHU0pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAA4Cbi4+Nls9mcbmFhYY7HDcNQfHy8IiIi5O/vr+joaO3evdtpHxkZGRo2bJgqVqyowMBAdenSRUeOHDE7FQAAgEuiKQUAAOBGbrrpJiUlJTluO3fudDw2depUvfrqq5o5c6YSExMVFhammJgYnTx50rFNXFycli1bpkWLFmnTpk06deqUOnXqpKysLFekAwAAUCBvVwcAAACA//H29nZaHZXLMAxNnz5dY8eOVbdu3SRJ8+bNU2hoqBYuXKhBgwYpNTVVs2fP1vvvv6927dpJkubPn6/IyEitWbNG7du3NzUXAACAi2GlFAAAgBv59ddfFRERoaioKD3wwAP6/fffJUkHDhxQcnKyYmNjHdv6+fmpdevW2rx5syRp+/btstvtTttERESoTp06jm0AAADcBSulAAAA3ETTpk313//+V9dff73+/PNPTZgwQc2bN9fu3buVnJwsSQoNDXV6TmhoqA4dOiRJSk5Olq+vr8qVK5dnm9znFyQjI0MZGRmO+2lpaZIku90uu91+xbldDXJfJ14v90etrIV6WQe1so6SrlVh90tTCgAAwE106NDB8fe6deuqWbNmuu666zRv3jzdeuutkiSbzeb0HMMw8oxdqDDbTJ48WePHj88zvnr1agUEBBQ2BUhKSEhwdQgoJGplLdTLOqiVdZRUrdLT0wu1HU0pAAAANxUYGKi6devq119/VdeuXSXlrIYKDw93bJOSkuJYPRUWFqbMzEydOHHCabVUSkqKmjdvftFjjRkzRiNHjnTcT0tLU2RkpGJjYxUSElKMWXkuu92uhIQExcTEyMfHx9Xh4CKolbVQL+ugVtZR0rXKXXF9KTSlAAAA3FRGRob27t2rli1bKioqSmFhYUpISFDDhg0lSZmZmVq/fr2mTJkiSWrcuLF8fHyUkJCg7t27S5KSkpK0a9cuTZ069aLH8vPzk5+fX55xHx8f/mNxmXjNrINaWQv1sg5qZR0lVavC7pOmFAAAgJsYPXq0OnfurCpVqiglJUUTJkxQWlqa+vXrJ5vNpri4OE2aNEk1a9ZUzZo1NWnSJAUEBKhnz56SpDJlymjgwIEaNWqUKlSooPLly2v06NGqW7eu42p8AAAA7oKmFAAAgJs4cuSIevToob///lvXXHONbr31Vm3ZskVVq1aVJD355JM6c+aMBg8erBMnTqhp06ZavXq1goODHfuYNm2avL291b17d505c0Zt27bV3Llz5eXl5aq0AAAA8kVTCgAAwE0sWrTooo/bbDbFx8crPj6+wG1Kly6tGTNmaMaMGcUcHQAAQPEq5eoAAAAAAAAAcPWhKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwHU0pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwHU0pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQubUrFx8fLZrM53cLCwlwZEgAAAAAAAEzg7eoAbrrpJq1Zs8Zx38vLy4XRAAAAAAAAwAwub0p5e3uzOgoAAAAAAOAq4/JzSv3666+KiIhQVFSUHnjgAf3++++uDgkAAAAAAAAlzKUrpZo2bar//ve/uv766/Xnn39qwoQJat68uXbv3q0KFSrk2T4jI0MZGRmO+2lpaZIku90uu91uWtxWl/ta8Zq5P2plHdTKOqiVtZR0vXgfAAAAuI5Lm1IdOnRw/L1u3bpq1qyZrrvuOs2bN08jR47Ms/3kyZM1fvz4POOrV69WQEBAicbqiRISElwdAgqJWlkHtbIOamUtJVWv9PT0EtkvAAAALs3l55Q6X2BgoOrWratff/0138fHjBnj1KxKS0tTZGSkYmNjFRISYlaYlme325WQkKCYmBj5+Pi4OhxcBLWyDmplHdTKWkq6XrmrrgEAAGA+t2pKZWRkaO/evWrZsmW+j/v5+cnPzy/PuI+PD/+xKAJeN+ugVtZBrayDWllLSdWL9wAAAIDruPRE56NHj9b69et14MABfffdd7r33nuVlpamfv36uTIsAAAAAAAAlDCXrpQ6cuSIevToob///lvXXHONbr31Vm3ZskVVq1Z1ZVgAAAAAAAAoYS5tSi1atMiVhwcAAAAAAICLuPTrewAAAAAAALg60ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwHU0pAAAANzV58mTZbDbFxcU5xgzDUHx8vCIiIuTv76/o6Gjt3r3b6XkZGRkaNmyYKlasqMDAQHXp0kVHjhwxOXoAAICLoykFAADghhITE/XOO++oXr16TuNTp07Vq6++qpkzZyoxMVFhYWGKiYnRyZMnHdvExcVp2bJlWrRokTZt2qRTp06pU6dOysrKMjsNAACAAtGUAgAAcDOnTp1Sr1699O6776pcuXKOccMwNH36dI0dO1bdunVTnTp1NG/ePKWnp2vhwoWSpNTUVM2ePVuvvPKK2rVrp4YNG2r+/PnauXOn1qxZ46qUAAAA8vB2dQAAAABwNmTIEN15551q166dJkyY4Bg/cOCAkpOTFRsb6xjz8/NT69attXnzZg0aNEjbt2+X3W532iYiIkJ16tTR5s2b1b59+3yPmZGRoYyMDMf9tLQ0SZLdbpfdbi/uFD1S7uvE6+X+qJW1UC/roFbWUdK1Kux+aUoBAAC4kUWLFun7779XYmJinseSk5MlSaGhoU7joaGhOnTokGMbX19fpxVWudvkPj8/kydP1vjx4/OMr169WgEBAZedx9UsISHB1SGgkKiVtVAv66BW1lFStUpPTy/UdjSlAAAA3MThw4c1YsQIrV69WqVLly5wO5vN5nTfMIw8Yxe61DZjxozRyJEjHffT0tIUGRmp2NhYhYSEFDKDq5vdbldCQoJiYmLk4+Pj6nBwEdTKWqiXdVAr6yjpWuWuuL4UmlIAAABuYvv27UpJSVHjxo0dY1lZWdqwYYNmzpypffv2ScpZDRUeHu7YJiUlxbF6KiwsTJmZmTpx4oTTaqmUlBQ1b968wGP7+fnJz88vz7iPjw//sbhMvGbWQa2shXpZB7WyjpKqVWH3yYnOAQAA3ETbtm21c+dO7dixw3Fr0qSJevXqpR07dqh69eoKCwtzWmqfmZmp9evXOxpOjRs3lo+Pj9M2SUlJ2rVr10WbUgAAAGZjpRQAAICbCA4OVp06dZzGAgMDVaFCBcd4XFycJk2apJo1a6pmzZqaNGmSAgIC1LNnT0lSmTJlNHDgQI0aNUoVKlRQ+fLlNXr0aNWtW1ft2rUzPScAAICC0JQCAACwkCeffFJnzpzR4MGDdeLECTVt2lSrV69WcHCwY5tp06bJ29tb3bt315kzZ9S2bVvNnTtXXl5eLowcAADAGU0pAAAAN7Zu3Tqn+zabTfHx8YqPjy/wOaVLl9aMGTM0Y8aMkg0OAADgCnBOKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwHU0pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwHU0pAAAAAAAAmI6mFAAAAAAAAExHUwoAAKAYxMfH69ChQ64OAwAAwDJoSgEAABSDTz/9VNddd53atm2rhQsX6uzZs64OCQAAwK3RlAIAACgG27dv1/fff6969erp8ccfV3h4uB577DElJia6OjQAAAC3RFMKAACgmNSrV0/Tpk3T0aNH9d577+no0aNq0aKF6tatq9dee02pqamuDhEAAMBt0JQCAAAoZtnZ2crMzFRGRoYMw1D58uU1a9YsRUZGavHixa4ODwAAwC3QlAIAACgm27dv19ChQxUeHq7HH39cDRs21N69e7V+/Xr9/PPPGjdunIYPH+7qMAEAANwCTSkAAIBiUK9ePd166606cOCAZs+ercOHD+ull15SjRo1HNv07dtXf/31lwujBAAAcB/erg4AAADAE9x333168MEHde211xa4zTXXXKPs7GwTowIAAHBfNKUAAC5nGIbOnTunrKysEj+W3W6Xt7e3zp49a8rxcGWutF5eXl7y9vaWzWYrgeicGYahcuXK5Rk/c+aM/u///k/PP/98iccAAHCNrKws2e12V4fhcsyzrMNd5lg0pQAALpWZmamkpCSlp6ebcjzDMBQWFqbDhw+b0qjAlSmOegUEBCg8PFy+vr7FHJ2z8ePH69FHH1VAQIDTeHp6usaPH09TCgA81KlTp3TkyBEZhuHqUFyOeZZ1uMsci6YUAMBlsrOzdeDAAXl5eSkiIkK+vr4lPoHJzs7WqVOnFBQUpFKlOLWiu7uSehmGoczMTP311186cOCAatasWaI1Nwwj3/fvjz/+qPLly5fYcQEArpOVlaUjR44oICBA11xzzVXfiGGeZR3uMseiKQUAcJnMzExlZ2crMjIyz+qSkpKdna3MzEyVLl2ayZIFXGm9/P395ePjo0OHDjn2U9zKlSsnm80mm82m66+/3uk/JFlZWTp16pQeffTRYj8uAMD17Ha7DMPQNddcI39/f1eH43LMs6zDXeZYNKUAAC7HpAUlqaTfX9OnT5dhGHrwwQc1fvx4lSlTxvGYr6+vqlWrpmbNmpVoDAAA17raV0jh6lQccyyaUgAAAFegX79+kqSoqCg1b95cPj4+Lo4IAADAGvhoGgAANxEdHa24uLhCb3/w4EHZbDbt2LGjxGLCxaWlpTn+3rBhQ505c0ZpaWn53gAA8GTR0dF6/PHHC7391TCPKYkcL3e+6O5YKQUA8AhZWdLGjVJSkhQeLrVsKXl5lcyxLrVEv1+/fpo7d+5l73fp0qWXtcomMjJSSUlJqlix4mUf63IcPHhQUVFR+uGHH9SgQYMSPZbVlCtXTklJSapUqZLKli2b73sj9wToXBobAFAQT5nHeHl5FfoqhGbPY3KVLVtWdevW1YsvvqjWrVuX6LFLwoXzxWrVqikuLs6yjSqaUgAAy1u6VBoxQjpy5H9jlStLr70mdetW/MdLSkpy/H3x4sV6/vnntW/fPsfYhSc6tdvthWo2Xe4V2ry8vBQWFnZZz0Hx+vrrrx11+/rrrzmnCADgsnnSPCY7O7vQq4PNnsesWbNGN910k1JSUvTMM8+oY8eO2rVrl1PDqrAyMzPl6+tbAlFemqdd0Zev7wEALG3pUunee50ncpJ09GjO+NKlxX/MsLAwx61MmTKy2WyO+2fPnlXZsmX14YcfKjo6WqVLl9b8+fN1/Phx9ejRQ5UrV1ZAQIDq1q2rDz74wGm/Fy7HrlatmiZNmqQHH3xQwcHBqlKlit555x3H4xcuCV+3bp1sNpu++uorNWnSRAEBAWrevLnTRFOSJkyYoEqVKik4OFgPPfSQnn766StaAZWRkaHhw4erUqVKKl26tG677TYlJiY6Hj9x4oR69erluDJRzZo1NWfOHEk5k7qhQ4cqPDxcpUuXVrVq1TR58uQix2K21q1by9s75zO+6OhotW7dusAbAAAX8rR5zPlf33O3eUyFChUUFhamevXq6e2331Z6erpWr14tSdqzZ486duyooKAghYaGqk+fPvr777+dchs6dKhGjhypihUrKiYmRlLOqrNZs2apQ4cO8vf3V1RUlD766KOLxnGxY61bt06+vr7auHGjY/tXXnlFFStWdDQTz58vRkdH69ChQ3r88ccdVwI+ffq0QkJC9PHHHzsd99NPP1VgYKBOnjx5ydfKTDSlAABuxTCk06cLd0tLk4YPz3lOfvuRcj55TEsr3P4Kudq8UJ566ikNHz5ce/fuVfv27XX27Fk1btxYn332mXbt2qVHHnlEffr00XfffXfR/bzyyitq0qSJfvjhBw0ePFiPPfaYfv7554s+Z+zYsXrllVe0bds2eXt768EHH3Q8tmDBAk2cOFFTpkzR9u3bVaVKFc2aNeuKcn3yySe1ZMkSzZs3T99//71q1Kih9u3b659//pEkPffcc9qzZ49WrlypvXv3atasWY6l+q+//rpWrFihDz/8UPv27dP8+fNVrVq1K4rHVZ577rl8v6KXmpqqHj16uCAiAIDZmMc4c9d5TEBAgKScVWBJSUlq3bq1GjRooG3btmnVqlX6888/1b17d6fnzJs3T97e3vrmm2/09ttvO8afe+453XPPPfrxxx/Vu3dv9ejRQ3v37s33uJc6Vm7DqU+fPkpNTdWPP/6osWPH6t1331V4eHie/S1dulSVK1fWCy+8oKSkJCUlJSkwMFAPPPCA4wPAXHPmzNG9996r4ODgy369SpRhYampqYYkIzU11dWhWEpmZqaxfPlyIzMz09Wh4BKolXVQq6I5c+aMsWfPHuPMmTOOsVOnDCNnWmX+7dSpy89hzpw5RpkyZRz3Dxw4YEgypk+ffsnnduzY0Rg1apTjfuvWrY0RI0Y47letWtXo3bu34352drZRqVIlY9asWU7H+uGHHwzDMIy1a9cakow1a9Y4nvP5558bkhyvcdOmTY0hQ4Y4xdGiRQujfv36BcZ54XHOd+rUKcPHx8dYsGCBYywzM9OIiIgwpk6dahiGYXTu3NkYMGBAvvseNmyYcfvttxvZ2dn5Pp6VlWWcOHHCyMrKKjC+S8nvfZarOOcSVapUMZo2bWrs37/fMbZ27VojMjLSuPXWW694/2ZjnnX5+F1gHdTKWty5Xhf+jrna5zHDhw93/N5213nMqVOnjEGDBhleXl7GTz/9ZDz33HNGbGys03MOHz5sSDL27dvnyK1BgwZ59i3JePTRR53GmjZtajz22GP5Hrswx8rIyDAaNmxodO/e3bjpppuMhx56yGn7/OaL06ZNc9rmu+++M7y8vIyjR48ahmEYf/31l+Hj42OsW7fOsY27zLGKtFLq8OHDOnLe+sKtW7cqLi7OaSkeAABXsyZNmjjdz8rK0sSJE1WvXj1VqFBBQUFBWr16tf7444+L7qdevXqOv+cur09JSSn0c3I/Vct9zr59+3TLLbc4bX/h/cvx22+/yW63q0WLFo4xHx8f3XLLLY5PCR977DEtWrRIDRo00JNPPqnNmzc7tu3fv7927NihG264QcOHD3cso7ein376SdWqVVODBg307rvv6oknnlBsbKz69++vTZs2uTo8AAAKzRPnMc2bN1dQUJCCg4P16aefau7cuapbt662b9+utWvXKigoyHG78cYbJeXMc3Jd+JrkatasWZ77Ba2UKsyxfH19NX/+fC1ZskRnzpzR9OnTC5Xf+W655RbddNNN+u9//ytJev/991WlShW1atXqsvdV0op0ovOePXs6luslJycrJiZGN910k+bPn6/k5GQ9//zzxR0nAOAqERAgnTpVuG03bJA6drz0dl98IeX+Ds49AWdISIhKlXL+bOb/r+QuFoGBgU73X3nlFU2bNk3Tp09X3bp1FRgYqLi4OGVmZl50PxeeWNRmsyk7O7vQz8k98fb5z7nwZNzGFaz3z31ufvvMHevQoYMOHTqkzz//XGvWrFHbtm01ZMgQvfzyy2rUqJEOHDiglStXas2aNerevbvatWuX5zwIVlCmTBktWrRIY8eO1aBBg+Tt7a2VK1eqbdu2rg4NAGCSkp7HXOrYxcUT5zGLFy9W7dq1VbZsWVWoUMExnp2drc6dO2vKlCl5nnP+V+YufE0upqALnxT2WLkf4P3zzz/6559/LuvYuR566CHNnDlTTz/9tObMmaMBAwa45QVZirRSateuXY5u5Icffqg6depo8+bNWrhwYZEuHQkAQC6bTQoMLNwtNjbn6jQF/X612aTIyJztCrO/kvw9vXHjRt11113q3bu36tevr+rVq+vXX38tuQMW4IYbbtDWrVudxrZt21bk/dWoUUO+vr5OK4Hsdru2bdumWrVqOcauueYa9e/fX/Pnz9f06dOdVleHhITo/vvv17vvvqvFixdryZIljvNRWc2MGTM0bdo09ejRQ9WrV9fw4cP1448/ujosAIBJmMeUrCuZx0RGRuq6665zakhJUqNGjbR7925Vq1ZNNWrUcLoVphm0ZcuWPPdzVz9dqDDH+u233/T444/r3Xff1a233qq+fftetJHn6+ub7zkte/furT/++EOvv/66du/erX79+l0yF1coUlPKbrfLz89PUs5lFbt06SJJuvHGG50uLwkAQEny8sq5XLKUdyKWe3/69JztXK1GjRpKSEjQ5s2btXfvXg0aNEjJycmmxzFs2DDNnj1b8+bN06+//qoJEybop59+KtQnZ/v27dOOHTucbj4+Pnrsscf0xBNPaNWqVdqzZ48efvhhpaena+DAgZKk559/Xp988on279+v3bt367PPPnM0rKZNm6ZFixbp559/1i+//KKPPvpIYWFhKlu2bEm+DCWiQ4cOGj9+vP773/9qwYIF+uGHH9SqVSvdeuutmjp1qqvDAwC4GeYxl+9K5jEFGTJkiP755x/16NFDW7du1e+//67Vq1frwQcfzLfZc6GPPvpI7733nn755ReNGzdOW7du1dChQ4t0rKysLPXp00exsbEaMGCA5syZo127dumVV14p8PjVqlXThg0bdPToUacrBpYrV07dunVznE6gcuXKl//imKBITambbrpJb731ljZu3KiEhATdcccdkqRjx47l6ToCAFCSunWTPv5YuvZa5/HKlXPGu3VzTVwXeu6559SoUSO1b99e0dHRCgsLU9euXU2Po1evXhozZoxGjx7t+Opc//79Vbp06Us+94EHHlDDhg2dbseOHdNLL72ke+65R3369FGjRo20f/9+ffnllypXrpyknE/wxowZo3r16qlVq1by8vLSokWLJElBQUGaMmWKmjRpoptvvlkHDx7UF198keerlVZw7tw5/fTTT7r33nslSf7+/po1a5Y+/vhjTZs2zcXRAQDcEfOYy3Ml85iCRERE6JtvvlFWVpbat2+vOnXqaMSIESpTpkyh5iPjx4/XokWLVK9ePc2bN08LFixQ7dq1i3SsiRMn6uDBg44V5WFhYfrPf/6jZ599Vjt27Mh3ny+88IIOHjyo6667Ttdcc43TYwMHDlRmZqbTFQzdjc0owokk1q1bp7vvvltpaWnq16+f3nvvPUnSM888o59//llLly4t9kDzk5aWpjJlyig1NVUhISGmHNMT2O12ffHFF+rYsWOe7/jCvVAr66BWRXP27FkdOHBAUVFRVzSZkKSsLGnjRikpSQoPl1q2zP+TxYudU+pqFRMTo7CwML3//vuuDiWP4qjXxd5nZs0l/v77b1WsWLHE9l8SmGddPn4XWAe1shZ3rldxzWUKO49xd66YZ7lyHmOz2bRs2TKXNOgKY8GCBRoxYoSOHTsmX19fp8fcZY5VpCNHR0fr77//1t9//+1oSEnSI488orfeeqsouwQA4Ip4eUnR0VKPHjl/WnEiZ4b09HS9+uqr2r17t37++WeNGzdOa9ascdvzDFjNxo0b1bt3bzVr1kxHjx6VlHPFm59//rlQz581a5bq1aunkJAQhYSEqFmzZlq5cqXjccMwFB8fr4iICPn7+ys6Olq7d+922kdGRoaGDRumihUrKjAwUF26dHG6ajIAwP0wjykc5jGFk56ert27d2vy5MkaNGhQnoaUOylSU+rMmTPKyMhwLMs/dOiQpk+frn379qlSpUrFGiAAACg+NptNX3zxhVq2bKnGjRvr008/1ZIlS9SuXTtXh2Z5S5YsUfv27eXv768ffvhBGRkZkqSTJ09q0qRJhdpH5cqV9dJLL2nbtm3atm2bbr/9dt11112OxtPUqVP16quvaubMmUpMTFRYWJhiYmJ08uRJxz7i4uK0bNkyLVq0SJs2bdKpU6fUqVOnQp0XAwAAd8Y8pnCmTp2qBg0aKDQ0VGPGjHF1OBflXZQn3XXXXerWrZseffRR/fvvv2ratKl8fHz0999/69VXX9Vjjz1W3HECAIBi4O/vrzVr1rg6DI80YcIEvfXWW+rbt6/jnFmS1Lx5c73wwguF2kfnzp2d7k+cOFGzZs3Sli1bVLt2bU2fPl1jx45Vt/9/kpF58+YpNDRUCxcu1KBBg5SamqrZs2fr/fffd0zQ58+fr8jISK1Zs0bt27cvpmwBADCfu81jinA2JFPEx8crPj7e1WEUSpGaUt9//73jhJ0ff/yxQkND9cMPP2jJkiV6/vnni9SUmjx5sp555hmNGDFC06dPL0pYAAAALrNv3z61atUqz3hISIj+/fffy95fVlaWPvroI50+fVrNmjXTgQMHlJycrNjYWMc2fn5+at26tTZv3qxBgwZp+/btstvtTttERESoTp062rx580WbUhkZGY7VXVLOuSCknHO52O32y47/apT7OvF6uT9qZS3uXC+73S7DMJSdna3s7GxXh+NyuU2a3NcE7qs4apWdnS3DMGS32+V1wXdOC/vzWqSmVHp6uoKDgyVJq1evVrdu3VSqVCndeuutOnTo0GXvLzExUe+8847q1atXlHAAAABcLjw8XPv371e1atWcxjdt2qTq1asXej87d+5Us2bNdPbsWQUFBWnZsmWqXbu2Nm/eLEkKDQ112j40NNQx/0pOTpavr6/jFAvnb3OpS3dPnjxZ48ePzzO+evVqBQQEFDp+SAkJCa4OAYVErazFHevl7e2tsLAwnTp1SpmZma4Ox22c/7VyuLcrqVVmZqbOnDmjDRs26Ny5c06PpaenF2ofRWpK1ahRQ8uXL9fdd9+tL7/8Uo8//rgkKSUl5bKvznLq1Cn16tVL7777riZMmFCUcAAAAFxu0KBBGjFihN577z3ZbDYdO3ZM3377rUaPHq3nn3++0Pu54YYbtGPHDv37779asmSJ+vXrp/Xr1zset9lsTtsbhpFn7EKF2WbMmDEaOXKk435aWpoiIyMVGxvL1fcKyW63KyEhQTExMW53hTA4o1bW4s71Onv2rA4fPqygoKArvpKwJzAMQydPnlRwcPAlf+/AtYqjVmfPnpW/v79atWqV79X3CqNITannn39ePXv21OOPP67bb79dzZo1k5TzSVrDhg0va19DhgzRnXfeqXbt2l2yKcWy8uLhzstf4YxaWQe1KhpXLHlnWbm1uMvS8sJ48sknlZqaqjZt2ujs2bNq1aqV/Pz8NHr0aA0dOrTQ+/H19VWNGjUkSU2aNFFiYqJee+01PfXUU5JyVkOFh4c7tk9JSXGsngoLC1NmZqZOnDjhtFoqJSVFzZs3v+hx/fz85Ofnl2fcx8fH7f4T6O54zayDWlmLO9YrKytLNptNpUqVUqlSRbqOmEfJ/V2d+5rAfRVHrUqVKiWbzZbvz2Zhf1aL1JS69957ddtttykpKUn169d3jLdt21Z33313ofezaNEiff/990pMTCzU9iwrL17uuPwV+aNW1kGtLo8rl7yzrNxaXL20vLAmTpyosWPHas+ePcrOzlbt2rUVFBR0Rfs0DEMZGRmKiopSWFiYEhISHB8CZmZmav369ZoyZYokqXHjxvLx8VFCQoK6d+8uSUpKStKuXbs0derUK0sOAACgmBWpKSXlfBIXFhamI0eOyGaz6dprr9Utt9xS6OcfPnxYI0aM0OrVqwu9zJFl5cXDnZe/whm1sg5qVTSuWPLOsnJrcZel5ZcjICBATZo0KdJzn3nmGXXo0EGRkZE6efKkFi1apHXr1mnVqlWy2WyKi4vTpEmTVLNmTdWsWVOTJk1SQECAevbsKUkqU6aMBg4cqFGjRqlChQoqX768Ro8erbp163K5bAAA4HaK1JTKzs7WhAkT9Morr+jUqVOSpODgYI0aNUpjx44t1NKv7du3KyUlRY0bN3aMZWVlacOGDZo5c6YyMjLyLLFnWXnx4nWzDmplHdTq8rhiybs7LSuPjo5WgwYNHFedrVatmuLi4hQXF1fgc2w2m5YtW6auXbte0bGLaz8lzV2WlhekW7duhd526dKll9zmzz//VJ8+fZSUlKQyZcqoXr16WrVqlWJiYiTlfEXwzJkzGjx4sE6cOKGmTZtq9erVjgvQSNK0adPk7e2t7t2768yZM2rbtq3mzp2bZ14FAMCVyG8eM2LECA0YMKDA51xt85iimjt3ruLi4op09d6CuOtrVqSm1NixYzV79my99NJLatGihQzD0DfffKP4+HidPXtWEydOvOQ+2rZtq507dzqNDRgwQDfeeKOeeuopJk4AgMuTlSVt3CglJUnh4VLLllIJ/S7p3Lmzzpw5ozVr1uR57Ntvv1Xz5s21fft2NWrU6LL2m5iYqMDAwOIKU5IUHx+v5cuXa8eOHU7jSUlJea7QVtxKYkLlbsqUKVOs+5s9e/ZFH7fZbIqPj1d8fHyB25QuXVozZszQjBkzijU2AEAJ8pB5jL+/f56vyl8JV89jzm+whYWFqWXLlpoyZYqioqJK9Ngl4fzX7ODBg4qKitKGDRvUokULl8ZVpKbUvHnz9J///EddunRxjNWvX1/XXnutBg8eXKimVHBwsOrUqeM0FhgYqAoVKuQZBwDgopYulUaMkI4c+d9Y5crSa69Jl7GSpbAGDhyobt266dChQ6patarTY++9954aNGhw2RM5SbrmmmuKK8RLCgsLM+1YnmzOnDmuDgEAYHUeNI/Jzs4uka/GX8iseUxISIj27dsnwzD0888/a9CgQerSpYt27NhRpIU0drvdZd+qcNe5X5HWwf/zzz+68cYb84zfeOON+ueff644KAAACm3pUunee50ncpJ09GjOeCG+MnW5OnXqpEqVKmnu3LlO4+np6Vq8eLEGDhyo48ePq0ePHqpcubICAgJUt25dffDBBxfdb7Vq1RxL4CXp119/dZwHqXbt2vmeSP+pp57S9ddfr4CAAFWvXl3PPfec44pyc+fO1fjx4/Xjjz/KZrPJZrM5YrbZbFq+fLljPzt37tTtt98uf39/VahQQY888ojjK/qS1L9/f3Xt2lUvv/yywsPDVaFCBQ0ZMuSKrl73xx9/6K677lJQUJBCQkLUvXt3/fnnn47Hf/zxR7Vt21aRkZEqW7asGjdurG3btkmSDh06pM6dO6tcuXIKDAzUTTfdpC+++KLIsRSnlJQUbdy4UZs2bVJKSoqrwwEAuDMPm8e89tprjvueMI+x2WwKCwtTeHi42rRpo3HjxmnXrl3av3+/JOnTTz9V48aNVbp0aVWvXl3jx493Wilms9n01ltv6a677lJgYKAmTJigdevWyWaz6fPPP1f9+vVVunRpNW3aNM83yS50sWO98MILioiI0PHjxx3bd+nSRa1atXI6FULua5a70qtVq1by8vJSdHS0NmzYIB8fHyUnJzsdd9SoUWrVqtVFY7sSRVopVb9+fc2cOVOvv/660/jMmTNVr169Igezbt26Ij8XAOAhDEMq7BXRsrKk4cNznpPffmy2nE8e27X73xL47Gzp9Omc+xeeoyggIOc5l+Dt7a2+fftq7ty5ev755x0n4P7oo4+UmZmpXr16KT09XY0bN9ZTTz2lkJAQff755+rTp4+qV6+upk2bXvIY2dnZ6tatmypWrKgtW7YoLS0t33NNBQcHa+7cuYqIiNDOnTv18MMPKzg4WE8++aTuv/9+7dq1S6tWrXIs0c/v62bp6em64447dOuttyoxMVEpKSl66KGHNHToUKcJ69q1axUeHq61a9dq//79uv/++9WgQQM9/PDDl8znQoZhqGvXrgoMDNT69et17tw5DR48WPfff79jPtCrVy81aNBAU6ZMUZkyZfTTTz85Pl0cMmSIMjMztWHDBgUGBmrPnj1XfJW7K5WWlqYhQ4Zo0aJFysrKkiR5eXnp/vvv1xtvvFHsX/UDALihkp7HXAzzmBKfx/j7+0vKWfH05Zdfqnfv3nr99dfVsmVL/fbbb3rkkUckSePGjXM8Z9y4cZo8ebKmTZsmLy8vHThwQJL0xBNP6LXXXlNYWJieeeYZdenSRb/88ku+K6kudayxY8dq1apVeuihh7Rs2TK99dZb2rBhg3788cd8z8m5detW3XLLLVq+fLluvvlmlS5dWuXLl1f16tX1/vvv64knnpAknTt3TvPnz9dLL71U6NfoshlFsG7dOiMwMNCoVauW8eCDDxoDBw40atWqZQQFBRkbNmwoyi6LJDU11ZBkpKammnZMT5CZmWksX77cyMzMdHUouARqZR3UqmjOnDlj7Nmzxzhz5sz/Bk+dMoycqZj5t1OnCh373r17DUnG119/7Rhr1aqV0aNHjwKf07FjR2PUqFGO+61btzZGjBjhuF+1alVj2rRphmEYxpdffml4eXkZhw8fdjy+cuVKQ5KxbNmyAo8xdepUo3Hjxo7748aNM+rXr59nu/P388477xjlypUzTp2X/+eff26UKlXKSE5ONgzDMPr162dUrVrVOHfunGOb++67z7j//vsLjGXOnDlGmTJl8n1s9erVhpeXl/HHH384xnbv3m1IMrZu3WoYhmEEBwcb7733nnHixAkjKyvL6fl169Y14uPjCzz2+fJ9n/1/xTmXuO+++4yaNWsaq1atMlJTU420tDRj1apVxg033GDcd999V7x/szHPunz8LrAOamUt7lyvPL9jrvJ5zKuvvmqcOHHCWLlypcfNYw4fPmzceuutRuXKlY2MjAyjZcuWxqRJk5ye8/777xvh4eFOccbFxTlts3btWkOSsWjRIsfY8ePHDX9/f2Px4sX5Hrswx/rtt9+M4OBg46mnnjICAgKM+fPnF/iaHThwwJBkbNiwwWmONWXKFKNWrVqO+8uXLzeCgoKcXtvzFcccq0hf32vdurV++eUX3X333fr333/1zz//qFu3btq9ezfnVgAAXBVuvPFGNW/eXO+9954k6bffftPGjRv14IMPSsq5suDEiRNVr149VahQQUFBQVq9erX++OOPQu1/7969qlKliipXruwYa9asWZ7tPv74Y912220KCwtTUFCQnnvuuUIf4/xj1a9f3+kk6y1atFB2drb27dvnGLvpppuczp8QHh5e5K+n7d27V5GRkYqMjHSM1a5dW2XLltXevXslSSNHjtQjjzyirl27asqUKfrtt98c2w4fPlwTJkxQixYtNG7cOP30009FiqM4ff7553rvvffUvn17hYSEKDg4WO3bt9e7776rzz//3NXhAQDgUNLzmJ9//tkj5jGpqakKCgpSYGCgIiMjlZmZqaVLl8rX11fbt2/XCy+8oKCgIMft4YcfVlJSktLPWy3XpEmTfPd9/utRvnx53XDDDY450IUKc6zq1avr5Zdf1pQpU9S5c2f16tXrornlp3///tq/f7+2bNkiKeccY927dy/2C/Gcr8jXwo6IiNDEiRO1ZMkSLV26VBMmTNCJEyc0b9684owPAHC1CQiQTp0q3K2w5xD64gvHc7LT0vTvkSPKTkvLu7+AgMsKdeDAgVqyZInS0tI0Z84cVa1aVW3btpUkvfLKK5o2bZqefPJJff3119qxY4fat2+vzMzMQu3byGcpv+2CJflbtmzRAw88oA4dOuizzz7TDz/8oLFjxxb6GOcf68J953fMC5eT22w2x3kKLldBxzx/PD4+Xjt37lRsbKy+/vpr1a5dW8uWLZMkPfTQQ/r999/Vp08f7dy5U02aNHH51eYqVKiQ79cKypQpU+JXCAIAuIkSnsdc9MY85qLHLMo8Jjg4WDt27NDOnTt16tQpbd++XTfffLOknK8ojh8/Xjt27HDcdu7cqV9//VWlS5d27ONyGjoF5VHYY23YsEFeXl46ePBgka6CWKlSJXXu3Flz5sxRSkqKvvjiC0ejsqQUuSkFAECJsNmkwMDC3WJjc65OU9D5E2w2KTIyZ7vC7K8Q52E4X/fu3eXl5aWFCxdq3rx5GjBggGMysXHjRt11113q3bu36tevr+rVq+vXX38t9L5r166tP/74Q8eOHXOMffvtt07bfPPNN6patarGjh2rJk2aqGbNmjp06JDTNr6+vo7zG13sWDt27NDp06ed9l2qVCldf/31hY75cuTmd/jwYcfYnj17lJqaqlq1ajnGrr/+eg0ePFhffvmlunXr5rQiOzIyUo8++qiWLl2qUaNG6d133y2RWAvr2Wef1ciRI5WUlOQYS05O1hNPPKHnnnvOhZEBAEzDPEaSVKtWLY+Yx5QqVUo1atRQ9erV8zSXGjVqpH379qlGjRp5bvmdx+lCuauRJOnEiRP65Zdf8r2gXGGPtXjxYi1dulTr1q3T4cOH9eKLLxZ4bF9fX0nK97V96KGHtGjRIr399tu67rrr1KJFi0vmciVoSgEArMvLK+dyyVLeiVju/enTC3dy0CIICgrS/fffr2eeeUbHjh1T//79HY/VqFFDCQkJ2rx5s/bu3atBgwbluZrJxbRr10433HCD+vbtqx9//FEbN27U2LFjnbapUaOG/vjjDy1atEi//fabXn/9dcdKolzVqlXTgQMHtGPHDv3999/KyMjIc6xevXqpdOnS6tevn3bt2qW1a9dq2LBh6tOnj0JDQy/vRblAVlaW06d6O3bs0J49e9SuXTvVq1dPvXr10vfff6+tW7eqb9++at26tZo0aaIzZ85o6NChWrdunf744w998803SkxMdDSs4uLi9OWXX+rAgQP6/vvv9fXXXzs1s1xh1qxZ2rJli6pWreqYKFapUkWbN2/W22+/rUaNGjluAAAwj3H/eczFPP/88/rvf/+r+Ph47d69W3v37tXixYv17LPPFur5L7zwgr766ivt2rVL/fv3V8WKFdW1a9ciHevIkSN67LHHNGXKFN12222aO3euJk+e7NT4Ol+lSpXk7++vNWvW6M8//1Rqaqrjsfbt26tMmTKaMGGCBgwYcHkvShHQlAIAWFu3btLHH0vXXus8Xrlyzni3biV6+IEDB+rEiRNq166dqlSp4hh/7rnn1KhRI7Vv317R0dEKCwsrcKKRn1KlSmnZsmXKyMjQLbfcooceekgTJ0502uauu+7S448/rqFDh6pBgwbavHlznhU599xzj+644w61adNG11xzTb6Xcw4ICNCXX36pf/75RzfffLPuvfdetW3bVjNnzry8FyMfp06dUsOGDZ1uHTt2dFyWuFy5cmrVqpXatWun6tWra/HixZJyrlp3/Phx9e/fXzfffLNjef/48eMl5TS7hgwZolq1aumOO+7QDTfcoDfffPOK470SXbt21ejRozV27Fj16dNHffr00dixYzV69GjdddddTjcAACQxj3HzeczFtG/fXp999pkSEhJ0880369Zbb9Wrr76qqlWrFur5L730kkaMGKHGjRsrKSlJK1ascKxgupxjGYah/v3765ZbbtHQoUMlSTExMRo6dKh69+6tU6dO5dmft7e3pk+frrlz56py5cpOc5NSpUqpf//+ysrKUt++fYvwylwem5Hflz0L0O0SPxD//vuv1q9ff8nldcUlLS1NZcqUUWpqqkJCQkw5piew2+364osv1LFjx3wvNwn3Qa2sg1oVzdmzZ3XgwAFFRUU5fR++SLKypI0bpaQkKTxcatky308Ws7OzlZaWppCQkEItrYZrFUe9LvY+K665RFZWljZt2qR69ep5zPmjmGddPn4XWAe1shZ3rlexzWUKOY9xd8yzLm3dunVq06aNTpw4obJly7osjovV6uGHH9aff/6pFStWXHQfxTHH8r6coPM7eeeFj5vRSQMAIA8vLyk62tVR4Crl5eWl9u3ba+/evR7TlAIAmIh5DNxAamqqEhMTtWDBAn3yySemHPOymlLnn1wUAAAA/1O3bl39/vvvioqKcnUoAAAAl+2uu+7S1q1bNWjQIMXExJhyzMtqSgEAACB/EydO1OjRo/Xiiy+qcePGea7Sw1fgAABAdHS0LuMsSqZat26d6cekKQUAAFAM7rjjDklSly5dHJfUliTDMGSz2Uw75yYAAIBV0JQCAAAoBmvXrnV1CAAAAJZCUwoA4HLuuoQZnsGs91fr1q1NOQ4AwP0wl8HVqDje91yjEQDgMrmXdU5PT3dxJPBkue8vMy4jvnHjRvXu3VvNmzfX0aNHJUnvv/++Nm3aVOLHBgCYz8vLS5KUmZnp4kgA8xXHHIuVUgAAl/Hy8lLZsmWVkpIiSQoICHA6F09JyM7OVmZmps6ePatSpfhsxt1dSb0Mw1B6erpSUlJUtmxZx38cSsqSJUvUp08f9erVS99//70yMjIkSSdPntSkSZP0xRdflOjxAQDm8/b2VkBAgP766y/5+Phc9XML5lnW4S5zLJpSAACXCgsLkyRHY6qkGYahM2fOyN/fv8QbYLhyxVGvsmXLOt5nJWnChAl666231LdvXy1atMgx3rx5c73wwgslfnwAgPlsNpvCw8N14MABHTp0yNXhuBzzLOtwlzkWTSkAgEvlTuYqVaoku91e4sez2+3asGGDWrVqZcrXuXBlrrRePj4+Jb5CKte+ffvUqlWrPOMhISH6999/TYkBAGA+X19f1axZk6/wiXmWlbjLHIumFADALXh5eZnSPPDy8tK5c+dUunRpJksWYKV6hYeHa//+/apWrZrT+KZNm1S9enXXBAUAMEWpUqVUunRpV4fhclb6vX21c5da8SVPAACAYjBo0CCNGDFC3333nWw2m44dO6YFCxZo9OjRGjx4sKvDAwAAcDuslAIAACgGTz75pNLS0tSmTRudPXtWrVq1kp+fn0aPHq2hQ4e6OjwAAAC3Q1MKAADgCqSnp+uJJ57Q8uXLZbfb1blzZ40aNUqSVLt2bQUFBbk4QgAAAPdEUwoAAOAKjBs3TnPnzlWvXr3k7++vhQsXKjs7Wx999JGrQwMAAHBrNKUAAACuwNKlSzV79mw98MADkqRevXqpRYsWysrKMu3KfwAAAFbEic4BAACuwOHDh9WyZUvH/VtuuUXe3t46duyYC6MCAABwfzSlAAAArkBWVpZ8fX2dxry9vXXu3DkXRQQAAGANfH0PAADgChiGof79+8vPz88xdvbsWT366KMKDAx0jC1dutQV4QEAALgtmlIAAABXoF+/fnnGevfu7YJIAAAArIWmFAAAwBWYM2eOq0MAAACwJM4pBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwHU0pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAABuYvLkybr55psVHBysSpUqqWvXrtq3b5/TNoZhKD4+XhEREfL391d0dLR2797ttE1GRoaGDRumihUrKjAwUF26dNGRI0fMTAUAAOCSaEoBAAC4ifXr12vIkCHasmWLEhISdO7cOcXGxur06dOObaZOnapXX31VM2fOVGJiosLCwhQTE6OTJ086tomLi9OyZcu0aNEibdq0SadOnVKnTp2UlZXlirQAAADy5e3qAAAAAJBj1apVTvfnzJmjSpUqafv27WrVqpUMw9D06dM1duxYdevWTZI0b948hYaGauHChRo0aJBSU1M1e/Zsvf/++2rXrp0kaf78+YqMjNSaNWvUvn170/MCAADIDyulAAAA3FRqaqokqXz58pKkAwcOKDk5WbGxsY5t/Pz81Lp1a23evFmStH37dtntdqdtIiIiVKdOHcc2AAAA7oCVUgAAAG7IMAyNHDlSt912m+rUqSNJSk5OliSFhoY6bRsaGqpDhw45tvH19VW5cuXybJP7/PxkZGQoIyPDcT8tLU2SZLfbZbfbrzyhq0Du68Tr5f6olbVQL+ugVtZR0rUq7H5pSgEAALihoUOH6qefftKmTZvyPGaz2ZzuG4aRZ+xCl9pm8uTJGj9+fJ7x1atXKyAgoJBRQ5ISEhJcHQIKiVpZC/WyDmplHSVVq/T09EJtR1MKAADAzQwbNkwrVqzQhg0bVLlyZcd4WFiYpJzVUOHh4Y7xlJQUx+qpsLAwZWZm6sSJE06rpVJSUtS8efMCjzlmzBiNHDnScT8tLU2RkZGKjY1VSEhIseXmyex2uxISEhQTEyMfHx9Xh4OLoFbWQr2sg1pZR0nXKnfF9aXQlAIAAHAThmFo2LBhWrZsmdatW6eoqCinx6OiohQWFqaEhAQ1bNhQkpSZman169drypQpkqTGjRvLx8dHCQkJ6t69uyQpKSlJu3bt0tSpUws8tp+fn/z8/PKM+/j48B+Ly8RrZh3Uylqol3VQK+soqVoVdp80pQAAANzEkCFDtHDhQn3yyScKDg52nAOqTJky8vf3l81mU1xcnCZNmqSaNWuqZs2amjRpkgICAtSzZ0/HtgMHDtSoUaNUoUIFlS9fXqNHj1bdunUdV+MDAABwBzSlAAAA3MSsWbMkSdHR0U7jc+bMUf/+/SVJTz75pM6cOaPBgwfrxIkTatq0qVavXq3g4GDH9tOmTZO3t7e6d++uM2fOqG3btpo7d668vLzMSgUAAOCSaEoBAAC4CcMwLrmNzWZTfHy84uPjC9ymdOnSmjFjhmbMmFGM0QEAABSvUq4OAAAAAAAAAFcfmlIAAAAAAAAwHU0pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJjOpU2pWbNmqV69egoJCVFISIiaNWumlStXujIkAAAAAAAAmMClTanKlSvrpZde0rZt27Rt2zbdfvvtuuuuu7R7925XhgUAAAAAAIAS5u3Kg3fu3Nnp/sSJEzVr1ixt2bJFN910k4uiAgAAAAAAQElzaVPqfFlZWfroo490+vRpNWvWzNXhAAAAAAAAoAS5vCm1c+dONWvWTGfPnlVQUJCWLVum2rVr57ttRkaGMjIyHPfT0tIkSXa7XXa73ZR4PUHua8Vr5v6olXVQK+ugVtZS0vXifQAAAOA6Lm9K3XDDDdqxY4f+/fdfLVmyRP369dP69evzbUxNnjxZ48ePzzO+evVqBQQEmBGuR0lISHB1CCgkamUd1Mo6qJW1lFS90tPTS2S/AAAAuDSXN6V8fX1Vo0YNSVKTJk2UmJio1157TW+//XaebceMGaORI0c67qelpSkyMlKxsbEKCQkxLWars9vtSkhIUExMjHx8fFwdDi6CWlkHtbIOamUtJV2v3FXXAAAAMJ/Lm1IXMgzD6St65/Pz85Ofn1+ecR8fH/5jUQS8btZBrayDWlkHtbKWkqoX7wEAAADXcWlT6plnnlGHDh0UGRmpkydPatGiRVq3bp1WrVrlyrAAAAAAAABQwlzalPrzzz/Vp08fJSUlqUyZMqpXr55WrVqlmJgYV4YFAAAAAACAEubSptTs2bNdeXgAAAAAAAC4SClXBwAAAAAAAICrD00pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwHU0pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAuJENGzaoc+fOioiIkM1m0/Lly50eNwxD8fHxioiIkL+/v6Kjo7V7926nbTIyMjRs2DBVrFhRgYGB6tKli44cOWJiFgAAAJdGUwoAAMCNnD59WvXr19fMmTPzfXzq1Kl69dVXNXPmTCUmJiosLEwxMTE6efKkY5u4uDgtW7ZMixYt0qZNm3Tq1Cl16tRJWVlZZqUBAABwSd6uDgAAAAD/06FDB3Xo0CHfxwzD0PTp0zV27Fh169ZNkjRv3jyFhoZq4cKFGjRokFJTUzV79my9//77ateunSRp/vz5ioyM1Jo1a9S+fXvTcgEAALgYmlIAAAAWceDAASUnJys2NtYx5ufnp9atW2vz5s0aNGiQtm/fLrvd7rRNRESE6tSpo82bNxfYlMrIyFBGRobjflpamiTJbrfLbreXUEaeJfd14vVyf9TKWqiXdVAr6yjpWhV2vzSlAAAALCI5OVmSFBoa6jQeGhqqQ4cOObbx9fVVuXLl8myT+/z8TJ48WePHj88zvnr1agUEBFxp6FeVhIQEV4eAQqJW1kK9rINaWUdJ1So9Pb1Q29GUAgAAsBibzeZ03zCMPGMXutQ2Y8aM0ciRIx3309LSFBkZqdjYWIWEhFxZwFcJu92uhIQExcTEyMfHx9Xh4CKolbVQL+ugVtZR0rXKXXF9KTSlAAAALCIsLExSzmqo8PBwx3hKSopj9VRYWJgyMzN14sQJp9VSKSkpat68eYH79vPzk5+fX55xHx8f/mNxmXjNrINaWQv1sg5qZR0lVavC7pOr7wEAAFhEVFSUwsLCnJbaZ2Zmav369Y6GU+PGjeXj4+O0TVJSknbt2nXRphQAAIDZWCkFAADgRk6dOqX9+/c77h84cEA7duxQ+fLlVaVKFcXFxWnSpEmqWbOmatasqUmTJikgIEA9e/aUJJUpU0YDBw7UqFGjVKFCBZUvX16jR49W3bp1HVfjAwAAcAc0pQAAANzItm3b1KZNG8f93PM89evXT3PnztWTTz6pM2fOaPDgwTpx4oSaNm2q1atXKzg42PGcadOmydvbW927d9eZM2fUtm1bzZ07V15eXqbnAwAAUBCaUgAAAG4kOjpahmEU+LjNZlN8fLzi4+ML3KZ06dKaMWOGZsyYUQIRAgAAFA/OKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwHU0pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADAdTSkAAAAAAACYjqYUAAAAAAAATEdTCgAAAAAAAKajKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pQAAAAAAAGA6mlIAAAAAAAAwnUubUpMnT9bNN9+s4OBgVapUSV27dtW+fftcGRIAAAAAAABM4NKm1Pr16zVkyBBt2bJFCQkJOnfunGJjY3X69GlXhgUAAAAAAIAS5u3Kg69atcrp/pw5c1SpUiVt375drVq1clFUAAAAAAAAKGludU6p1NRUSVL58uVdHAkAAAAAAABKkktXSp3PMAyNHDlSt912m+rUqZPvNhkZGcrIyHDcT0tLkyTZ7XbZ7XZT4vQEua8Vr5n7o1bWQa2sg1pZS0nXi/cBAACA67hNU2ro0KH66aeftGnTpgK3mTx5ssaPH59nfPXq1QoICCjJ8DxSQkKCq0NAIVEr66BW1kGtrKWk6pWenl4i+wUAAMCluUVTatiwYVqxYoU2bNigypUrF7jdmDFjNHLkSMf9tLQ0RUZGKjY2ViEhIWaE6hHsdrsSEhIUExMjHx8fV4eDi6BW1kGtrINaWUtJ1yt31TUAAADM59KmlGEYGjZsmJYtW6Z169YpKirqotv7+fnJz88vz7iPjw//sSgCXjfroFbWQa2sg1pZS0nVi/cAAACA67i0KTVkyBAtXLhQn3zyiYKDg5WcnCxJKlOmjPz9/V0ZGgAAAAAAAEqQS6++N2vWLKWmpio6Olrh4eGO2+LFi10ZFgAAAAAAAEqYy7++BwAAAAAAgKuPS1dKAQAAAAAA4OpEUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApqMpBQAAAAAAANPRlAIAAAAAAIDpaEoBAAAAAADAdDSlAAAAAAAAYDqaUgAAAAAAADCdt6sDcFdZWdLGjVJSkhQeLrVsKXl5uToqAAAAAAAAz0BTKh9Ll0ojRkhHjvxvrHJl6bXXpG7dXBcXAAAAAACAp+DrexdYulS6917nhpQkHT2aM750qWviAgAAAAAA8CQ0pc6TlZWzQsow8j6WOxYXl7MdAAAAAAAAio6v751n48a8K6TOZxjS4cPSffdJt98u3XCDdP31UmSkVIr2HgAAAAAAQKHRlDpPUlLhtlu2LOeWq3RpqUaNnAZVbqMq91axYsnECgAAAAAAYGU0pc4THl647e6/Xzp7VvrlF2n//py/79qVc7tQ+fLOTarcplWNGlJAQPHGDwAAAAAAYBU0pc7TsmXOVfaOHs3/vFI2W87jCxZIXl45Y+fOSYcO5TSocm/79uX8efiw9M8/0pYtObcLRUbmv7qqWrX/7R8AAMDTZGXlnDYhKSnnQ8GWLZn7AABwNaIpdR4vL+m113KusmezOTembLacP6dPd540eXtL112Xc+vQwXl/6ek5K6lym1TnN61OnMhpWh0+LH31lfPzfH1z9nfh6qrrr5cqVfpfLEWRlSWtX2/Thg3XKjDQpjZtrD8J9NSJrSfWSvLMelEr66BW1uKp9braLV2ac2GZ88/jWblyzhysWzfXxXWlPPX96on/vlAra/HEelEr66BWJjAsLDU11ZBkpKamFut+lywxjMqVDSOnLZVzi4zMGS8uf/1lGN98Yxhz5hjGmDGGcc89hlGnjmH4+Tkf98JbSIhhNGliGL16Gcb48YbxwQeGsX27YZw8WbS8Klcu3rzM5ok5GQZ5WYkn5mQYnpmXJ+ZkGOR1pUpqLuEJSuK1WbLEMGy2vPMbmy3nZtX3LT+H1uGJORkGeVmJJ+ZkGJ6ZlyfmZBjuN8eiKVWAc+cMY+1aw1i4MOfPc+eK/RD5ysoyjIMHDWP1asOYMcMwhg0zjPbtDSMqKv9J3Pm3iAjDiI42jEceMYxXXjGMTz81jH37DCMz0zMngZ6Yk2GQl5V4Yk6G4Zl5eWJOhkFexYGmVMGK+7U5dy7vJPjC+kZGmjfnKi78HFqHJ+ZkGORlJZ6Yk2F4Zl6emJNhuOcci6/vFcDLS4qONv+4pUpJVavm3GJinB87e1b67TfnrwLmfh3wr7+kY8dybuvWOT/Pyyvv1xFz5Y498oiUmZlzfCvIzpaGDPGsnCTyslJenpiT5Jl5eWJO0tWbl80mxcVJd93lGcvnryYbNzp/Ze9ChpFzWoOYmJyvSNhsOe/dUqUK9/fCblec+zIMafToq+/nULJeXp6Yk0ReVsrLE3OSPDMvT8xJct85ls0w8gvJGtLS0lSmTBmlpqYqJCTE1eG41IkT0q+/Op9oPfeWnu7q6AAAKF5r1xbPh0eePpd488039X//939KSkrSTTfdpOnTp6tly5aFem5xvzYffCD17HnFuwEAACXI7DkWK6U8RLly0i235NzOZxjSm29KQ4deeh+1akmhoSUTX3H7809p795Lb2elnCTyslJenpiT5Jl5eWJOEnklJZV8LFa3ePFixcXF6c0331SLFi309ttvq0OHDtqzZ4+qVKliejzh4YXbbujQnAu+ZGfnzGOysy/+98JuVxL7OnJE+umnS+fkqT+HVsrLE3OSyMtKeXliTpJn5uWJOUluPMcqvm8Mmo/zQBTO2rUFn7/h/Nvata6OtPA8MSfDIC8r5eWJORmGZ+bliTkZBnkVV16ePJe45ZZbjEcffdRp7MYbbzSefvrpQj2/pM4pVdA5Mq14Til+Dl0daeF5Yk6GQV5WyssTczIMz8zLE3MyDPedY/H1vatAVpZUrZp09GjO2+xCNlvOpZgPHLDO+Tk8MSeJvKyUlyfmJHlmXp6Yk0RexZWXp84lMjMzFRAQoI8++kh33323Y3zEiBHasWOH1q9ff8l9lMRrs3SpdO+9OX8/v742W86fH38sdetWLIcyBT+H1snLE3OSyMtKeXliTpJn5uWJOUnuO8fi63tXAS8v6bXXciaBF57wPHcSOH26tX6gPDEnibyslJcn5iR5Zl6emJNEXlbLy2x///23srKyFHrB9wpCQ0OVnJyc73MyMjKUkZHhuJ+WliZJstvtstvtxRJX587SokU2jRzppaNHbY7xa6819MorWerc2VAxHco0r7xi0wMPeP3/9+v/crLZct68L7+cpexsQ9nZroqwaDwxL0/MSSIvK+XliTlJnpmXJ+YkmZtXYecOrJS6iixdKo0Y4Xzlm8jInMm9lT6VPJ8n5iSRl5V4Yk6SZ+bliTlJ5HWlPHUucezYMV177bXavHmzmjVr5hifOHGi3n//ff388895nhMfH6/x48fnGV+4cKECAgKKNb6sLGnPngo6caK0ypU7q9q1j1u60fjtt+H6z3/q6vhxf8dYxYrpGjhwl5o1s+4J0DwxL0/MSSIvK/HEnCTPzMsTc5LMyys9PV09e/a85ByLptRVJitLWrv2nFau3KEOHRqoTRtvS08CpZycNm7MOSFbeLjUsqVnfILuibWSPLNe1Mo6qJW1mFEvT51LFOXre/mtlIqMjNTff//tUa9NScnKktaty1JCwi7FxNRRdLSXx/wcbtpkc/z7cttthuXzolbW4on1olbWQa2KLi0tTRUrVuTre3Dm5SW1bm3o9Omjat26vkf8QHl5Fc8lK92NJ9ZK8sx6USvroFbW4qn1MoOvr68aN26shIQEp6ZUQkKC7rrrrnyf4+fnJz8/vzzjPj4+8vHxKbFYPYWPj9S2rZSRcVRt29b3mNfMx0dq187VURQvamUtnlgvamUd1OpKjlG4fdKUAgAA8EAjR45Unz591KRJEzVr1kzvvPOO/vjjDz366KOuDg0AAEASTSkAAACPdP/99+v48eN64YUXlJSUpDp16uiLL75Q1apVXR0aAACAJJpSAAAAHmvw4MEaPHiwq8MAAADIVylXBwAAAAAAAICrD00pAAAAAAAAmI6mFAAAAAAAAExHUwoAAAAAAACmoykFAAAAAAAA09GUAgAAAAAAgOloSgEAAAAAAMB0NKUAAAAAAABgOppSAAAAAAAAMB1NKQAAAAAAAJiOphQAAAAAAABMR1MKAAAAAAAApvN2dQBXwjAMSVJaWpqLI7EWu92u9PR0paWlycfHx9Xh4CKolXVQK+ugVtZS0vXKnUPkzinwP8yzLh//vlgHtbIW6mUd1Mo63GWOZemm1MmTJyVJkZGRLo4EAABY2cmTJ1WmTBlXh+FWmGcBAIArdak5ls2w8EeD2dnZOnbsmIKDg2Wz2VwdjmWkpaUpMjJShw8fVkhIiKvDwUVQK+ugVtZBraylpOtlGIZOnjypiIgIlSrFWQ3Oxzzr8vHvi3VQK2uhXtZBrazDXeZYll4pVapUKVWuXNnVYVhWSEgI/1BYBLWyDmplHdTKWkqyXqyQyh/zrKLj3xfroFbWQr2sg1pZh6vnWHwkCAAAAAAAANPRlAIAAAAAAIDpaEpdhfz8/DRu3Dj5+fm5OhRcArWyDmplHdTKWqgXrIT3q3VQK2uhXtZBrazDXWpl6ROdAwAAAAAAwJpYKQUAAAAAAADT0ZQCAAAAAACA6WhKAQAAAAAAwHQ0pa4SkydP1s0336zg4GBVqlRJXbt21b59+1wdFgph8uTJstlsiouLc3UoKMDRo0fVu3dvVahQQQEBAWrQoIG2b9/u6rBwgXPnzunZZ59VVFSU/P39Vb16db3wwgvKzs52dWhXvQ0bNqhz586KiIiQzWbT8uXLnR43DEPx8fGKiIiQv7+/oqOjtXv3btcEC+SDeZZ1Mc9yb8yxrIE5lntz93kWTamrxPr16zVkyBBt2bJFCQkJOnfunGJjY3X69GlXh4aLSExM1DvvvKN69eq5OhQU4MSJE2rRooV8fHy0cuVK7dmzR6+88orKli3r6tBwgSlTpuitt97SzJkztXfvXk2dOlX/93//pxkzZrg6tKve6dOnVb9+fc2cOTPfx6dOnapXX31VM2fOVGJiosLCwhQTE6OTJ0+aHCmQP+ZZ1sQ8y70xx7IO5ljuzd3nWVx97yr1119/qVKlSlq/fr1atWrl6nCQj1OnTqlRo0Z68803NWHCBDVo0EDTp093dVi4wNNPP61vvvlGGzdudHUouIROnTopNDRUs2fPdozdc889CggI0Pvvv+/CyHA+m82mZcuWqWvXrpJyPr2LiIhQXFycnnrqKUlSRkaGQkNDNWXKFA0aNMiF0QL5Y57l/phnuT/mWNbBHMs63HGexUqpq1RqaqokqXz58i6OBAUZMmSI7rzzTrVr187VoeAiVqxYoSZNmui+++5TpUqV1LBhQ7377ruuDgv5uO222/TVV1/pl19+kST9+OOP2rRpkzp27OjiyHAxBw4cUHJysmJjYx1jfn5+at26tTZv3uzCyICCMc9yf8yz3B9zLOtgjmVd7jDP8jblKHArhmFo5MiRuu2221SnTh1Xh4N8LFq0SN9//70SExNdHQou4ffff9esWbM0cuRIPfPMM9q6dauGDx8uPz8/9e3b19Xh4TxPPfWUUlNTdeONN8rLy0tZWVmaOHGievTo4erQcBHJycmSpNDQUKfx0NBQHTp0yBUhARfFPMv9Mc+yBuZY1sEcy7rcYZ5FU+oqNHToUP3000/atGmTq0NBPg4fPqwRI0Zo9erVKl26tKvDwSVkZ2erSZMmmjRpkiSpYcOG2r17t2bNmsWEyc0sXrxY8+fP18KFC3XTTTdpx44diouLU0REhPr16+fq8HAJNpvN6b5hGHnGAHfAPMu9Mc+yDuZY1sEcy/pcOc+iKXWVGTZsmFasWKENGzaocuXKrg4H+di+fbtSUlLUuHFjx1hWVpY2bNigmTNnKiMjQ15eXi6MEOcLDw9X7dq1ncZq1aqlJUuWuCgiFOSJJ57Q008/rQceeECSVLduXR06dEiTJ09mwuTGwsLCJOV8khceHu4YT0lJyfOpHuBqzLPcH/Ms62COZR3MsazLHeZZnFPqKmEYhoYOHaqlS5fq66+/VlRUlKtDQgHatm2rnTt3aseOHY5bkyZN1KtXL+3YsYOJkptp0aJFnst+//LLL6pataqLIkJB0tPTVaqU8689Ly8vLlfs5qKiohQWFqaEhATHWGZmptavX6/mzZv/v/buJrSJNI7j+G/qS0xCkL5p6qGoGK2N6EFFWt/QgrRCoVIpaJRUD6U1lip4kaqtgjlJ9RYIaC9WCj2o1VKFiqeCVNBqwCoI6kWKioJGMZc+exCym63rurvuzES/HxiYmScz+U8u+fHnyRMHKwN+R87KH+Ss/EHGyh9krPzlhpzFTKlfRCwW06VLl3T16lUFAoHsb0fnzp0rr9frcHX4o0AgMG0NCr/fr+LiYtamcKHDhw+rurpa8XhcTU1NGhsbUzKZVDKZdLo0/El9fb1Onz6t8vJyhcNh3b9/Xz09Pdq/f7/Tpf3y0um0nj59mj1+9uyZxsfHVVRUpPLych06dEjxeFyhUEihUEjxeFw+n0+7d+92sGrgd+Ss/EHOyh9krPxBxnI31+csg1+CpK9uvb29TpeG77B582bT0dHhdBn4C9euXTMrVqwwHo/HVFRUmGQy6XRJ+Ir379+bjo4OU15ebubMmWMWL15sOjs7TSaTcbq0X97t27e/+h0VjUaNMcZMTU2Zrq4uEwwGjcfjMZs2bTKpVMrZooE/IGflN3KWe5Gx8gMZy93cnrMsY4yxp/0FAAAAAAAAfMGaUgAAAAAAALAdTSkAAAAAAADYjqYUAAAAAAAAbEdTCgAAAAAAALajKQUAAAAAAADb0ZQCAAAAAACA7WhKAQAAAAAAwHY0pQAAAAAAAGA7mlIAIMmyLF25csXpMgAAAH4qZCwA30JTCoDjmpubZVnWtK22ttbp0gAAAPIWGQuA2810ugAAkKTa2lr19vbmnPN4PA5VAwAA8HMgYwFwM2ZKAXAFj8ejYDCYsxUWFkr6Mu07kUiorq5OXq9XixYt0sDAQM71qVRKW7duldfrVXFxsVpaWpROp3Nec+HCBYXDYXk8HpWVlengwYM542/evNGOHTvk8/kUCoU0ODiYHXv37p0ikYhKS0vl9XoVCoWmBTwAAAC3IWMBcDOaUgDywvHjx9XY2KgHDx5oz5492rVrlyYmJiRJnz59Um1trQoLC3X37l0NDAxoZGQkJxAlEgnFYjG1tLQolUppcHBQS5YsyXmPkydPqqmpSQ8fPtT27dsViUT09u3b7Ps/evRIw8PDmpiYUCKRUElJiX0fAAAAwP+AjAXAUQYAHBaNRs2MGTOM3+/P2U6dOmWMMUaSaW1tzblm3bp1pq2tzRhjTDKZNIWFhSadTmfHh4aGTEFBgZmcnDTGGLNgwQLT2dn5lzVIMseOHcsep9NpY1mWGR4eNsYYU19fb/bt2/djHhgAAMAGZCwAbseaUgBcYcuWLUokEjnnioqKsvtVVVU5Y1VVVRofH5ckTUxMaNWqVfL7/dnx9evXa2pqSk+ePJFlWXr58qVqamq+WcPKlSuz+36/X4FAQK9evZIktbW1qbGxUffu3dO2bdvU0NCg6urqf/WsAAAAdiFjAXAzmlIAXMHv90+b6v13LMuSJBljsvtfe43X6/2u+82aNWvatVNTU5Kkuro6vXjxQkNDQxoZGVFNTY1isZjOnDnzj2oGAACwExkLgJuxphSAvHDnzp1pxxUVFZKkyspKjY+P6+PHj9nx0dFRFRQUaOnSpQoEAlq4cKFu3br1n2ooLS1Vc3OzLl68qHPnzimZTP6n+wEAADiNjAXAScyUAuAKmUxGk5OTOedmzpyZXehyYGBAa9as0YYNG9TX16exsTGdP39ekhSJRNTV1aVoNKru7m69fv1a7e3t2rt3r+bPny9J6u7uVmtrq+bNm6e6ujp9+PBBo6Ojam9v/676Tpw4odWrVyscDiuTyej69etavnz5D/wEAAAAfjwyFgA3oykFwBVu3LihsrKynHPLli3T48ePJX3515b+/n4dOHBAwWBQfX19qqyslCT5fD7dvHlTHR0dWrt2rXw+nxobG9XT05O9VzQa1efPn3X27FkdOXJEJSUl2rlz53fXN3v2bB09elTPnz+X1+vVxo0b1d/f/wOeHAAA4P9DxgLgZpYxxjhdBAB8i2VZunz5shoaGpwuBQAA4KdBxgLgNNaUAgAAAAAAgO1oSgEAAAAAAMB2/HwPAAAAAAAAtmOmFAAAAAAAAGxHUwoAAAAAAAC2oykFAAAAAAAA29GUAgAAAAAAgO1oSgEAAAAAAMB2NKUAAAAAAABgO5pSAAAAAAAAsB1NKQAAAAAAANiOphQAAAAAAABs9xs3xdP7ogtjvwAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_validation_curves(training_losses, validation_losses, training_perplexities, validation_perplexities)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T01:13:13.789043Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Example: Using pretrained GPT-2 with Cosine Similarity for Recipe Generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "3'th index 1024 of condition tensor does not match the other tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[65], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m tfidf_vectorizer, tfidf_matrix \u001B[38;5;241m=\u001B[39m prepare_similarity_matrix(recipes)\n\u001B[0;32m----> 3\u001B[0m recipe_text \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_recipe_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_ingredients\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecipes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtfidf_vectorizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtfidf_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(recipe_text)\n",
      "Cell \u001B[0;32mIn[34], line 38\u001B[0m, in \u001B[0;36mgenerate_recipe_text\u001B[0;34m(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix, model, tokenizer)\u001B[0m\n\u001B[1;32m     36\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m encoded[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     37\u001B[0m pad_token_id \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mpad_token_id\n\u001B[0;32m---> 38\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_return_sequences\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mno_repeat_ngram_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m generated_text \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Remove repetitions from the directions in the generated text\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/generation/utils.py:1479\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1462\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massisted_decoding(\n\u001B[1;32m   1463\u001B[0m         input_ids,\n\u001B[1;32m   1464\u001B[0m         candidate_generator\u001B[38;5;241m=\u001B[39mcandidate_generator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1475\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1476\u001B[0m     )\n\u001B[1;32m   1477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mGREEDY_SEARCH:\n\u001B[1;32m   1478\u001B[0m     \u001B[38;5;66;03m# 11. run greedy search\u001B[39;00m\n\u001B[0;32m-> 1479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgreedy_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m        \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mCONTRASTIVE_SEARCH:\n\u001B[1;32m   1493\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/generation/utils.py:2340\u001B[0m, in \u001B[0;36mGenerationMixin.greedy_search\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   2337\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m   2339\u001B[0m \u001B[38;5;66;03m# forward pass to get next token\u001B[39;00m\n\u001B[0;32m-> 2340\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2341\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2343\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2344\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2345\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[1;32m   2348\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# don't waste resources running the code we don't need\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:1074\u001B[0m, in \u001B[0;36mGPT2LMHeadModel.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1066\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1067\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1068\u001B[0m \u001B[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001B[39;00m\n\u001B[1;32m   1069\u001B[0m \u001B[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001B[39;00m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1074\u001B[0m transformer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1088\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1089\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m transformer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1091\u001B[0m \u001B[38;5;66;03m# Set device for model parallelism\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:888\u001B[0m, in \u001B[0;36mGPT2Model.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    876\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    877\u001B[0m         block\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    878\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    885\u001B[0m         output_attentions,\n\u001B[1;32m    886\u001B[0m     )\n\u001B[1;32m    887\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 888\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_past\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_past\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    899\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:390\u001B[0m, in \u001B[0;36mGPT2Block.forward\u001B[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    388\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m    389\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_1(hidden_states)\n\u001B[0;32m--> 390\u001B[0m attn_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_past\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_past\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    398\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_outputs[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# output_attn: a, present, (attentions)\u001B[39;00m\n\u001B[1;32m    399\u001B[0m outputs \u001B[38;5;241m=\u001B[39m attn_outputs[\u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:331\u001B[0m, in \u001B[0;36mGPT2Attention.forward\u001B[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    329\u001B[0m     attn_output, attn_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 331\u001B[0m     attn_output, attn_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    333\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_heads(attn_output, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\n\u001B[1;32m    334\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc_proj(attn_output)\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:202\u001B[0m, in \u001B[0;36mGPT2Attention._attn\u001B[0;34m(self, query, key, value, attention_mask, head_mask)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;66;03m# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\u001B[39;00m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;66;03m# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\u001B[39;00m\n\u001B[1;32m    201\u001B[0m     mask_value \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfull([], mask_value, dtype\u001B[38;5;241m=\u001B[39mattn_weights\u001B[38;5;241m.\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mattn_weights\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 202\u001B[0m     attn_weights \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_weights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattn_weights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;66;03m# Apply the attention mask\u001B[39;00m\n\u001B[1;32m    206\u001B[0m     attn_weights \u001B[38;5;241m=\u001B[39m attn_weights \u001B[38;5;241m+\u001B[39m attention_mask\n",
      "\u001B[0;31mRuntimeError\u001B[0m: 3'th index 1024 of condition tensor does not match the other tensors"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer, tfidf_matrix = prepare_similarity_matrix(recipes)\n",
    "\n",
    "recipe_text = generate_recipe_text(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix, model, tokenizer)\n",
    "print(recipe_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T01:13:30.401790Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-p2r-py",
   "language": "python",
   "display_name": "Python [conda env:p2r] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
