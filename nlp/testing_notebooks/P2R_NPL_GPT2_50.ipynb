{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Plate2Recipe NLP Model: \n",
    "Recipe Generation from Ingredients List using GPT-2 and TF-IDF Similarity Matching\n",
    "\n",
    "@Author: Nellie Cordova"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NLP Model\n",
    "- Assume list of ingredients is provided, use this to generate the recipe. \n",
    "- Match input list of ingredients with the ingredients in the dataset and generate the recipe\n",
    "- Approach:\n",
    "        -- TF-IDF: Vectorization of ingredients.\n",
    "        -- Cosine Similarity: to find the recipe in the dataset that has the highest similarity to the provided ingredients.\n",
    "        -- GPT2 model: Generate the recipe based on the matched recipe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.8.19 (default, Mar 20 2024, 15:27:52) \n",
      "[Clang 14.0.6 ]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=8, micro=19, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"Python version\")\n",
    "print(sys.version)\n",
    "print(\"Version info.\")\n",
    "print(sys.version_info)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:21:07.824856Z",
     "start_time": "2024-04-28T00:21:07.812956Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "!pip install bayesian-optimization\n",
    "from bayes_opt import BayesianOptimization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:21:12.057072Z",
     "start_time": "2024-04-28T00:21:12.052896Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Collection and Preprocessing\n",
    "\n",
    "- Data loading: *use full_dataset.csv for NLP* (https://drive.google.com/drive/folders/1ui_zS11_ENZTCNLUsgg_UwAYr-ZaLbac)\n",
    "- Data cleaning\n",
    "- Data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTORCH_MPS_HIGH_WATERMARK_RATIO set to: 0.0\n"
     ]
    }
   ],
   "source": [
    "# MPS memory management - Used to solve RuntimeError: MPS backend out of memory\n",
    "# source: https://pnote.eu/notes/pytorch-mac-setup/\n",
    "os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'\n",
    "\n",
    "# Check that the environment variable is set correctly\n",
    "print(\"PYTORCH_MPS_HIGH_WATERMARK_RATIO set to:\", os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:21:15.523377Z",
     "start_time": "2024-04-28T00:21:15.516872Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Set device to maximize performance\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "device = torch.device(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:21:17.026335Z",
     "start_time": "2024-04-28T00:21:17.024107Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:21:18.065164Z",
     "start_time": "2024-04-28T00:21:18.060393Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Helper function to clear unused memory\n",
    "def clear_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    elif torch.backends.mps.is_available():\n",
    "        torch.mps.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:21:19.963937Z",
     "start_time": "2024-04-28T00:21:19.959450Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "clear_memory()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:21:21.062976Z",
     "start_time": "2024-04-28T00:21:21.055078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "user_ingredients = ['avocado', 'rice', 'shrimp', 'tomato']\n",
    "dataset_path = './data/full_dataset.csv'\n",
    "\n",
    "n_recipes = 50\n",
    "model_path = \"gpt2\"\n",
    "best_model_path = f'./models/best_gpt2_model_{n_recipes}'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:21:23.088882Z",
     "start_time": "2024-04-28T00:21:23.084160Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "def load_data(filepath):\n",
    "    return pd.read_csv(filepath).drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "recipes = load_data(dataset_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:21:50.928831Z",
     "start_time": "2024-04-28T00:21:24.518885Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "                          title  \\\n0        Tj'S Lentil Haystacks    \n1  California Hot Chicken Salad   \n2           Miniature Ham Puffs   \n3    Candy-Bar-Topped Brownies    \n4   German Chocolate Pound Cake   \n\n                                         ingredients  \\\n0  [\"cooked lentils\", \"chopped onion\", \"minced ga...   \n1  [\"3 cups cooked diced chicken\", \"2 cups thinly...   \n2  [\"1 c. water\", \"1/2 c. margarine or butter\", \"...   \n3  [\"3/4 cup (1 1/2 sticks) unsalted butter, dice...   \n4  [\"2 c. sugar\", \"1 c. butter\", \"4 eggs\", \"2 tsp...   \n\n                                          directions  \\\n0  [\"Saute onion and garlic until soft. Prepare r...   \n1  [\"Toss with a fork; chicken, celery, almonds, ...   \n2  [\"Heat oven to 400\\u00b0.\", \"Heat water and ma...   \n3  [\"Preheat oven to 325\\u00b0F. Line 13x9x2-inch...   \n4  [\"Melt chocolate in butter.\", \"Cool and add re...   \n\n                                                link    source  \\\n0  www.epicurious.com/recipes/member/views/tjs-le...  Gathered   \n1  www.food.com/recipe/california-hot-chicken-sal...  Gathered   \n2    www.cookbooks.com/Recipe-Details.aspx?id=972270  Gathered   \n3  www.epicurious.com/recipes/food/views/candy-ba...  Gathered   \n4    www.cookbooks.com/Recipe-Details.aspx?id=711693  Gathered   \n\n                                                 NER  \n0  [\"onion\", \"garlic\", \"chicken broth\", \"tomato s...  \n1  [\"chicken\", \"celery\", \"almond\", \"pimiento\", \"m...  \n2  [\"water\", \"margarine\", \"flour\", \"eggs\", \"ham\",...  \n3  [\"unsalted butter\", \"chocolate\", \"espresso pow...  \n4  [\"sugar\", \"butter\", \"eggs\", \"vanilla\", \"butter...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>ingredients</th>\n      <th>directions</th>\n      <th>link</th>\n      <th>source</th>\n      <th>NER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tj'S Lentil Haystacks</td>\n      <td>[\"cooked lentils\", \"chopped onion\", \"minced ga...</td>\n      <td>[\"Saute onion and garlic until soft. Prepare r...</td>\n      <td>www.epicurious.com/recipes/member/views/tjs-le...</td>\n      <td>Gathered</td>\n      <td>[\"onion\", \"garlic\", \"chicken broth\", \"tomato s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>California Hot Chicken Salad</td>\n      <td>[\"3 cups cooked diced chicken\", \"2 cups thinly...</td>\n      <td>[\"Toss with a fork; chicken, celery, almonds, ...</td>\n      <td>www.food.com/recipe/california-hot-chicken-sal...</td>\n      <td>Gathered</td>\n      <td>[\"chicken\", \"celery\", \"almond\", \"pimiento\", \"m...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Miniature Ham Puffs</td>\n      <td>[\"1 c. water\", \"1/2 c. margarine or butter\", \"...</td>\n      <td>[\"Heat oven to 400\\u00b0.\", \"Heat water and ma...</td>\n      <td>www.cookbooks.com/Recipe-Details.aspx?id=972270</td>\n      <td>Gathered</td>\n      <td>[\"water\", \"margarine\", \"flour\", \"eggs\", \"ham\",...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Candy-Bar-Topped Brownies</td>\n      <td>[\"3/4 cup (1 1/2 sticks) unsalted butter, dice...</td>\n      <td>[\"Preheat oven to 325\\u00b0F. Line 13x9x2-inch...</td>\n      <td>www.epicurious.com/recipes/food/views/candy-ba...</td>\n      <td>Gathered</td>\n      <td>[\"unsalted butter\", \"chocolate\", \"espresso pow...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>German Chocolate Pound Cake</td>\n      <td>[\"2 c. sugar\", \"1 c. butter\", \"4 eggs\", \"2 tsp...</td>\n      <td>[\"Melt chocolate in butter.\", \"Cool and add re...</td>\n      <td>www.cookbooks.com/Recipe-Details.aspx?id=711693</td>\n      <td>Gathered</td>\n      <td>[\"sugar\", \"butter\", \"eggs\", \"vanilla\", \"butter...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set a seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "recipes_shuffled = recipes.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Select 50% of the recipes randomly\n",
    "num_recipes_to_keep = n_recipes #int(len(recipes_shuffled) * 0.5)\n",
    "recipes = recipes_shuffled[:num_recipes_to_keep]\n",
    "\n",
    "# Print the new DataFrame\n",
    "recipes.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:31:45.044587Z",
     "start_time": "2024-04-28T00:31:45.026309Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        10 non-null     object\n",
      " 1   ingredients  10 non-null     object\n",
      " 2   directions   10 non-null     object\n",
      " 3   link         10 non-null     object\n",
      " 4   source       10 non-null     object\n",
      " 5   NER          10 non-null     object\n",
      "dtypes: object(6)\n",
      "memory usage: 608.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(recipes.info())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:31:46.732149Z",
     "start_time": "2024-04-28T00:31:46.721160Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Tokenize, compute TF-IDF and prepare the similarity measure"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:57:24.385130Z",
     "start_time": "2024-04-27T22:57:24.361939Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_path, padding_side='left')\n",
    "    return model, tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:31:52.728144Z",
     "start_time": "2024-04-28T00:31:52.721786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def prepare_similarity_matrix(recipes):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(recipes['NER'])\n",
    "    return tfidf_vectorizer, tfidf_matrix\n",
    "\n",
    "tfidf_vectorizer, tfidf_matrix = prepare_similarity_matrix(recipes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:31:53.072908Z",
     "start_time": "2024-04-28T00:31:53.063551Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def find_best_match(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix):\n",
    "    \"\"\"Calculate cosine similarity and return the best recipe match.\"\"\"\n",
    "    user_input_tfidf = tfidf_vectorizer.transform([' '.join(user_ingredients)])\n",
    "    cos_similarities = cosine_similarity(user_input_tfidf, tfidf_matrix)\n",
    "    best_recipe_index = cos_similarities.argmax()\n",
    "    return recipes.iloc[best_recipe_index]\n",
    "\n",
    "def remove_repetitions(text):\n",
    "    \"\"\"Helper function to remove repeated sentences in a list of directions.\"\"\"\n",
    "    seen = set()\n",
    "    result = []\n",
    "    for item in text:\n",
    "        if item not in seen:\n",
    "            seen.add(item)\n",
    "            result.append(item)\n",
    "    return result\n",
    "\n",
    "def generate_recipe_text(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix, model, tokenizer):\n",
    "    # Find the recipe that matches the user ingredients\n",
    "    best_recipe = find_best_match(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix)\n",
    "\n",
    "    # Parse ingredients and directions from the dataframe\n",
    "    ingredients_list = ast.literal_eval(best_recipe['ingredients'])\n",
    "    directions_list = ast.literal_eval(best_recipe['directions'])\n",
    "\n",
    "    # Reformat input to the model\n",
    "    ingredients_text = \"Ingredients:\\n\" + \"\\n\".join([f\"- {ingredient}\" for ingredient in ingredients_list])\n",
    "    directions_text = \"Directions:\\n\" + \"\\n\".join([f\"Step {i+1}: {step}\" for i, step in enumerate(directions_list)])\n",
    "    prompt_text = f\"Recipe Title: {best_recipe['title']}\\n\\n{ingredients_text}\\n\\n{directions_text}\"\n",
    "\n",
    "    # Generate the recipe text\n",
    "    encoded = tokenizer.encode_plus(prompt_text, return_tensors=\"pt\", padding='max_length', truncation=True)\n",
    "    input_ids = encoded['input_ids'].to(device)\n",
    "    attention_mask = encoded['attention_mask'].to(device)\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask, pad_token_id=pad_token_id, max_length=1024 + 50, num_return_sequences=1, no_repeat_ngram_size=2)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # Remove repetitions from the directions in the generated text\n",
    "    final_text_lines = generated_text.split('\\n')\n",
    "    final_text_lines = remove_repetitions(final_text_lines)\n",
    "\n",
    "    return \"\\n\".join(final_text_lines)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:31:57.780350Z",
     "start_time": "2024-04-28T00:31:57.773419Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Prepare data for training the GPT-2 model.\n",
    "- DataLoader creation for training and validation sets.\n",
    "- Model Training & Validation methods"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:59:10.944443Z",
     "start_time": "2024-04-27T22:59:10.939867Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoded['input_ids'].flatten(),\n",
    "            'attention_mask': encoded['attention_mask'].flatten(),\n",
    "            'labels': encoded['input_ids'].flatten()  # Labels for language modeling\n",
    "        }\n",
    "\n",
    "\n",
    "def create_data_loaders(recipes, batch_size, tokenizer, max_length):\n",
    "    # Combine title, ingredients, and directions into a single text input for each recipe\n",
    "    combined_texts = recipes.apply(lambda row: f\"Recipe Title: {row['title']} Ingredients: {row['ingredients']} Directions: {row['directions']}\", axis=1)\n",
    "    \n",
    "    # Split data into training and validation sets\n",
    "    train_texts, val_texts = train_test_split(combined_texts, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create Dataset objects\n",
    "    train_dataset = RecipeDataset(train_texts.tolist(), tokenizer, max_length)\n",
    "    val_dataset = RecipeDataset(val_texts.tolist(), tokenizer, max_length)\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:31:58.786445Z",
     "start_time": "2024-04-28T00:31:58.774735Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def train_and_validate(model, recipes, tokenizer, device, best_params):\n",
    "    # Cast batch size and num_train_epochs from best_params\n",
    "    batch_size = int(best_params.get('batch_size', 4))\n",
    "    num_train_epochs = int(best_params.get('num_train_epochs', 10))\n",
    "    learning_rate = best_params.get('learning_rate', 1e-5)\n",
    "    weight_decay = best_params.get('weight_decay', 0)  # Default to 0 if not specified\n",
    "    warmup_steps = int(best_params.get('warmup_steps', 0))  # Default to 0 if not specified\n",
    "\n",
    "\n",
    "    # Create data loaders with the best batch size\n",
    "    train_loader, val_loader = create_data_loaders(recipes, batch_size, tokenizer, max_length=512)\n",
    "\n",
    "    # Set up the optimizer and scheduler using the best learning rate\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    total_steps = len(train_loader) * num_train_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "    \n",
    "    # Use gradient accumulation to handle memory limits\n",
    "    accumulation_steps = 4  # Adjust based on your specific memory constraints\n",
    "\n",
    "\n",
    "    # Lists to store per-epoch metrics\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    training_perplexities = []\n",
    "    validation_perplexities = []\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_train_epochs):\n",
    "        total_loss = 0\n",
    "        model.zero_grad()\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / accumulation_steps  # Normalize the loss to account for accumulation\n",
    "            \n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            if (step + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "            # loss.backward()\n",
    "            # optimizer.step()\n",
    "            # scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_ppl = torch.exp(torch.tensor(avg_train_loss)).item()\n",
    "        training_losses.append(avg_train_loss)\n",
    "        training_perplexities.append(train_ppl)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_ppl = torch.exp(torch.tensor(avg_val_loss)).item()\n",
    "        validation_losses.append(avg_val_loss)\n",
    "        validation_perplexities.append(val_ppl)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_train_epochs} | Train Loss: {avg_train_loss:.3f} | Train PPL: {train_ppl:.3f} | Val Loss: {avg_val_loss:.3f} | Val PPL: {val_ppl:.3f}\")\n",
    "        \n",
    "        # Clear memory at the end of each epoch\n",
    "        clear_memory()\n",
    "\n",
    "    return training_losses, validation_losses, training_perplexities, validation_perplexities"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:31:59.252698Z",
     "start_time": "2024-04-28T00:31:59.246713Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_validation_curves(training_losses, validation_losses, training_perplexities, validation_perplexities):\n",
    "    epochs = range(1, len(training_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, training_losses, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, validation_losses, 'ro-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, training_perplexities, 'bo-', label='Training Perplexity')\n",
    "    plt.plot(epochs, validation_perplexities, 'ro-', label='Validation Perplexity')\n",
    "    plt.title('Training and Validation Perplexity')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Perplexity')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:31:59.614640Z",
     "start_time": "2024-04-28T00:31:59.604546Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model optimization with Bayesian Optimization: \n",
    "This approach combines traditional NLP techniques for ingredient matching with advanced language generation capabilities of GPT-2\n",
    "\n",
    "- Prepare data for fine-tuning: tokenize and format the data suitable for GPT-2\n",
    "- Hyperparameter Tuning: Explore different learning rates, batch sizes, and number of epochs\n",
    "    - Bayesian Optimization uses a probabilistic model to guide the search for the best hyperparameters. It balances exploration and exploitation to find the optimal hyperparameters efficiently. \n",
    "\n",
    "- Training: Train the model with recipes data, monitoring for convergence and performance.\n",
    "- Evaluation: Evaluate the model using validation data and metrics like perplexity.\n",
    "- Visualization of Results: Use plots to show training losses and evaluation metrics."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-27T22:59:28.160404Z",
     "start_time": "2024-04-27T22:59:28.156625Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Optimizer Selection\n",
    "- Adam is a popular choice due to its effectiveness in handling sparse gradients and adaptive learning rate techniques.\n",
    "\n",
    "Learning Rates\n",
    "- Initial Value: Starting learning rate in the range of 2e-5 to 5e-5, which are common starting points for fine-tuning language models.\n",
    "- Decay Strategy: Reduce the learning rate gradually as training progresses. This helps in fine-tuning the model to achieve better performance as it converges.\n",
    "- Warm-up Steps: Implementing a warm-up period for the learning rate can help stabilize the model's training early in the process, gradually increasing the learning rate from zero to the initial set learning rate.\n",
    "\n",
    "Batch Sizes\n",
    "- Size Range: Experiment with batch sizes, starting from smaller batches like 4 or 8, up to larger batches if your hardware supports it (e.g., 16, 32). Larger batch sizes provide a more stable gradient, but they require more memory.\n",
    "- Gradient Accumulation: If memory limits batch size, used to simulate larger batches. This means updating model weights less frequently, accumulating gradients over multiple forward passes.\n",
    "\n",
    "Number of Epochs\n",
    "- Epoch Count: Number of epochs is increased based on the initial results and if the model has not started overfitting. (See how quickly the model learns)\n",
    "- Early Stopping: Halt training when the validation metric (like perplexity or validation loss) stops improving. This prevents overfitting and saves computational resources.\n",
    "\n",
    "Weight Decay \n",
    "- (L2 Regularization): Prevents overfitting by penalizing large weights. Helps maintain a balance between model complexity and dataset simplicity.\n",
    "\n",
    "Gradient Clipping: \n",
    "- Prevents exploding gradients. By setting a threshold for gradient clipping, we ensure that gradients exceeding this threshold are scaled down to maintain stability in the training process.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def tune_model(learning_rate, weight_decay, num_train_epochs, warmup_steps, batch_size):\n",
    "    batch_size = int(batch_size)\n",
    "    num_train_epochs = int(num_train_epochs)\n",
    "    warmup_steps = int(warmup_steps)\n",
    "    \n",
    "    train_loader, val_loader = create_data_loaders(recipes, batch_size, tokenizer, max_length=512)\n",
    "    \n",
    "    # Set up optimizer and scheduler\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    total_steps = len(train_loader) * num_train_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "\n",
    "    # Define gradient accumulation steps to handle memory limits\n",
    "    accumulation_steps = 4  # Adjust based on your specific memory constraints\n",
    "    patience_limit = 3  # Early stopping after 3 epochs with no improvement\n",
    "    min_val_loss = float('inf')\n",
    "    gradient_clipping_norm = 1.0  # Common value for clipping gradients\n",
    "    patience = 0\n",
    "        \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(num_train_epochs):\n",
    "        total_loss = 0\n",
    "        model.zero_grad()\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss / accumulation_steps  # Normalize the loss to account for accumulation\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if (step + 1) % accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping_norm)\n",
    "                \n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Early stopping logic\n",
    "        if avg_val_loss < min_val_loss:\n",
    "            min_val_loss = avg_val_loss\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= patience_limit:\n",
    "                print(f\"Stopping early at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.3f}, Val Loss: {avg_val_loss:.3f}\")\n",
    "        \n",
    "        # Clear memory at the end of each epoch\n",
    "        clear_memory()\n",
    "\n",
    "    return -min_val_loss  # Maximizing the negative loss in Bayesian optimization"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:32:06.040320Z",
     "start_time": "2024-04-28T00:32:06.033884Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, tokenizer = load_model(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token as EOS token\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:32:09.658960Z",
     "start_time": "2024-04-28T00:32:07.911799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... | num_tr... | warmup... | weight... |\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch 1: Train Loss: 1.740, Val Loss: 6.382\n",
      "| \u001B[0m1        \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m55.71    \u001B[0m | \u001B[0m7.231e-05\u001B[0m | \u001B[0m1.001    \u001B[0m | \u001B[0m3.023e+03\u001B[0m | \u001B[0m0.001553 \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.627, Val Loss: 6.382\n",
      "Epoch 2: Train Loss: 1.653, Val Loss: 6.382\n",
      "Epoch 3: Train Loss: 1.653, Val Loss: 6.382\n",
      "Stopping early at epoch 4\n",
      "| \u001B[0m2        \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m15.45    \u001B[0m | \u001B[0m1.944e-05\u001B[0m | \u001B[0m4.11     \u001B[0m | \u001B[0m3.968e+03\u001B[0m | \u001B[0m0.005434 \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.751, Val Loss: 6.382\n",
      "Epoch 2: Train Loss: 1.653, Val Loss: 6.382\n",
      "Epoch 3: Train Loss: 1.653, Val Loss: 6.382\n",
      "| \u001B[0m3        \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m100.8    \u001B[0m | \u001B[0m9.492e-05\u001B[0m | \u001B[0m3.107    \u001B[0m | \u001B[0m9.329e+03\u001B[0m | \u001B[0m0.002628 \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.895, Val Loss: 6.382\n",
      "Epoch 2: Train Loss: 1.653, Val Loss: 6.382\n",
      "Epoch 3: Train Loss: 1.653, Val Loss: 6.382\n",
      "Stopping early at epoch 4\n",
      "| \u001B[0m4        \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m4.021    \u001B[0m | \u001B[0m6.524e-05\u001B[0m | \u001B[0m8.357    \u001B[0m | \u001B[0m4.758    \u001B[0m | \u001B[0m0.009484 \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.725, Val Loss: 6.382\n",
      "Epoch 2: Train Loss: 1.653, Val Loss: 6.382\n",
      "Epoch 3: Train Loss: 1.653, Val Loss: 6.382\n",
      "Stopping early at epoch 4\n",
      "| \u001B[0m5        \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m4.903    \u001B[0m | \u001B[0m7.827e-05\u001B[0m | \u001B[0m5.232    \u001B[0m | \u001B[0m9.98e+03 \u001B[0m | \u001B[0m0.005804 \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.731, Val Loss: 6.382\n",
      "Epoch 2: Train Loss: 1.653, Val Loss: 6.382\n",
      "Epoch 3: Train Loss: 1.653, Val Loss: 6.382\n",
      "Stopping early at epoch 4\n",
      "| \u001B[0m6        \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m126.4    \u001B[0m | \u001B[0m3.082e-05\u001B[0m | \u001B[0m7.784    \u001B[0m | \u001B[0m84.42    \u001B[0m | \u001B[0m0.006311 \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.678, Val Loss: 6.382\n",
      "Epoch 2: Train Loss: 1.653, Val Loss: 6.382\n",
      "Epoch 3: Train Loss: 1.653, Val Loss: 6.382\n",
      "Stopping early at epoch 4\n",
      "| \u001B[0m7        \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m127.2    \u001B[0m | \u001B[0m2.219e-05\u001B[0m | \u001B[0m7.743    \u001B[0m | \u001B[0m6.464e+03\u001B[0m | \u001B[0m0.002704 \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.757, Val Loss: 6.382\n",
      "Epoch 2: Train Loss: 1.653, Val Loss: 6.382\n",
      "Epoch 3: Train Loss: 1.653, Val Loss: 6.382\n",
      "Stopping early at epoch 4\n",
      "| \u001B[0m8        \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m125.8    \u001B[0m | \u001B[0m1.789e-05\u001B[0m | \u001B[0m8.991    \u001B[0m | \u001B[0m9.985e+03\u001B[0m | \u001B[0m0.001547 \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.801, Val Loss: 6.382\n",
      "Epoch 2: Train Loss: 1.653, Val Loss: 6.382\n",
      "Epoch 3: Train Loss: 1.653, Val Loss: 6.382\n",
      "Stopping early at epoch 4\n",
      "| \u001B[0m9        \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m4.256    \u001B[0m | \u001B[0m6.411e-05\u001B[0m | \u001B[0m9.757    \u001B[0m | \u001B[0m7.01e+03 \u001B[0m | \u001B[0m0.009319 \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.717, Val Loss: 6.382\n",
      "Epoch 2: Train Loss: 1.653, Val Loss: 6.382\n",
      "| \u001B[0m10       \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m126.9    \u001B[0m | \u001B[0m8.55e-05 \u001B[0m | \u001B[0m2.354    \u001B[0m | \u001B[0m3.224    \u001B[0m | \u001B[0m0.00748  \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.751, Val Loss: 6.382\n",
      "| \u001B[0m11       \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m128.0    \u001B[0m | \u001B[0m7.257e-05\u001B[0m | \u001B[0m1.743    \u001B[0m | \u001B[0m3.191e+03\u001B[0m | \u001B[0m0.004457 \u001B[0m |\n",
      "Epoch 1: Train Loss: 1.730, Val Loss: 6.382\n",
      "| \u001B[0m12       \u001B[0m | \u001B[0m-6.382   \u001B[0m | \u001B[0m6.205    \u001B[0m | \u001B[0m9.021e-05\u001B[0m | \u001B[0m1.385    \u001B[0m | \u001B[0m9.994e+03\u001B[0m | \u001B[0m0.002833 \u001B[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define parameter bounds\n",
    "pbounds = {\n",
    "    'learning_rate': (1e-6, 1e-4),\n",
    "    'batch_size': (4, 128),\n",
    "    'num_train_epochs': (1, 10),\n",
    "    'weight_decay': (1e-4, 1e-2),\n",
    "    'warmup_steps': (0, 10000),\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=tune_model,\n",
    "    pbounds=pbounds,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=10,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:40:06.076092Z",
     "start_time": "2024-04-28T00:38:52.892719Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:\n",
      "- Learning Rate: 7.231212485077366e-05\n",
      "- Batch Size: 55\n",
      "- Training Epochs: 1\n",
      "- Weight Decay: 0.0015528833190894193\n",
      "- Warmup Steps: 3023\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recipes used: {n_recipes}\")\n",
    "print(f\"Best model in: {best_model_path}\")\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(f\"- Learning Rate: {best_params['learning_rate']}\")\n",
    "print(f\"- Batch Size: {int(best_params['batch_size'])}\")\n",
    "print(f\"- Training Epochs: {int(best_params['num_train_epochs'])}\")\n",
    "print(f\"- Weight Decay: {best_params['weight_decay']}\")\n",
    "print(f\"- Warmup Steps: {int(best_params['warmup_steps'])}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:40:18.541127Z",
     "start_time": "2024-04-28T00:40:18.528538Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Optimized Model Training and Validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model, tokenizer = load_model(best_model_path)\n",
    "best_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:41:19.933370Z",
     "start_time": "2024-04-28T00:41:18.574017Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Train Loss: 1.318 | Train PPL: 3.738 | Val Loss: 3.482 | Val PPL: 32.519\n"
     ]
    }
   ],
   "source": [
    "best_batch_size = int(best_params['batch_size'])\n",
    "train_loader, val_loader = create_data_loaders(recipes, best_batch_size, tokenizer, max_length=512)\n",
    "\n",
    "training_losses, validation_losses, training_perplexities, validation_perplexities = train_and_validate(best_model, recipes, tokenizer, device, best_params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T00:41:28.942581Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing Results\n",
    "\n",
    "- Training Loss: Plot the training and validation loss over epochs to visualize learning progress and diagnose issues like overfitting or underfitting.\n",
    "- BLEU Scores or Perplexity Over Time: Similarly, track and plot BLEU scores or perplexity over epochs to assess language model performance improvements."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_validation_curves(training_losses, validation_losses, training_perplexities, validation_perplexities)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T00:41:42.400615Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Example: Generating a Recipe with Optimized model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model, tokenizer = load_model(best_model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "best_model.to(device)\n",
    "\n",
    "tfidf_vectorizer, tfidf_matrix = prepare_similarity_matrix(recipes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:41:50.865752Z",
     "start_time": "2024-04-28T00:41:49.503103Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe Title: Tj'S Lentil Haystacks \n",
      "\n",
      "Ingredients:\n",
      "- cooked lentils\n",
      "- chopped onion\n",
      "- minced garlic\n",
      "- 1/2 c chicken broth\n",
      "- 1/2 c tomato sauce\n",
      "- brown rice\n",
      "- lemon/olive oil\n",
      "- toppings like: feta, avocado, zucchini, eggplant, salsa, mango salsa -- good way to use up veggies\n",
      "Directions:\n",
      "Step 1: Saute onion and garlic until soft. Prepare rice.\n",
      "Step 2: Add lentils, broth, and marinara to onion and garlic. Cook until warm.\n",
      "Step 3: Put down cooked rice, top with lentils and toppings. Drizzle w lemon juice/olive oil.\n"
     ]
    }
   ],
   "source": [
    "# Generate the recipe\n",
    "recipe_text = generate_recipe_text(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix, best_model, tokenizer)\n",
    "\n",
    "print(recipe_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T00:41:51.056305Z",
     "start_time": "2024-04-28T00:41:50.868358Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### If best N epochs = 1, then train for 1 epoch to visualize the training process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# Train for 1 epoch to visualize the training process\n",
    "\n",
    "def train_for_one_epoch(model, train_loader, val_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:  # Log every 10 batches\n",
    "            print(f'Batch {batch_idx + 1}, Loss: {loss.item()}')\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    \n",
    "    print('Training for 1 Epoch:')\n",
    "    print(f'- Average Training Loss: {avg_train_loss}')\n",
    "    print(f'- Validation Loss: {avg_val_loss}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T00:50:51.376853Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1 Epoch:\n",
      "- Average Training Loss: 6.456393718719482\n",
      "- Validation Loss: 6.381645679473877\n"
     ]
    }
   ],
   "source": [
    "best_batch_size = int(best_params['batch_size'])\n",
    "train_loader_1E, val_loader_1E = create_data_loaders(recipes, best_batch_size, tokenizer, max_length=512)\n",
    "\n",
    "optimizer = torch.optim.AdamW(best_model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
    "train_for_one_epoch(model, train_loader_1E, val_loader_1E, optimizer, device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T00:50:52.557360Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/nc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/generation/utils.py:1141: UserWarning: Input length of input_ids is 512, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'perplexity': 32.51880950736368, 'bleu': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "# Ensure that NLTK resources are downloaded\n",
    "# nltk.download('punkt')\n",
    "\n",
    "def calculate_bleu(references, hypotheses):\n",
    "    \"\"\"\n",
    "    Calculate BLEU score between actual and predicted sentences.\n",
    "    \"\"\"\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    return corpus_bleu([[ref.split()] for ref in references], [hyp.split() for hyp in hypotheses], smoothing_function=smoothie)\n",
    "\n",
    "\n",
    "def evaluate_model(model, tokenizer, device, val_loader):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation set after one epoch of training.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    hypotheses = []\n",
    "    references = []\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Generate text from input ids\n",
    "            generated_ids = model.generate(input_ids, attention_mask=attention_mask)\n",
    "            generated_text = [tokenizer.decode(g_id, skip_special_tokens=True) for g_id in generated_ids]\n",
    "            actual_text = [tokenizer.decode(a_id, skip_special_tokens=True) for a_id in labels]\n",
    "            \n",
    "            hypotheses.extend(generated_text)\n",
    "            references.extend(actual_text)\n",
    "\n",
    "    # Calculate Perplexity \n",
    "    perplexity = np.exp(total_loss / len(val_loader))\n",
    "    \n",
    "    # Calculate BLEU score\n",
    "    bleu_score = calculate_bleu(references, hypotheses)\n",
    "    \n",
    "    return {\n",
    "        'perplexity': perplexity,\n",
    "        'bleu': bleu_score,\n",
    "    }\n",
    "\n",
    "\n",
    "results = evaluate_model(best_model, tokenizer, device, val_loader_1E)\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T01:02:13.048383Z",
     "start_time": "2024-04-28T01:02:10.118526Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-trained GPT-2 Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the GPT-2 model and tokenizer\n",
    "# model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model, tokenizer = load_model('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token as EOS token\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T01:04:36.461346Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 1.735 | Train PPL: 5.671 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 2/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 3/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 4/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 5/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 6/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 7/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 8/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 9/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n",
      "Epoch 10/10 | Train Loss: 1.653 | Train PPL: 5.224 | Val Loss: 6.382 | Val PPL: 590.899\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "train_loader, val_loader = create_data_loaders(recipes, batch_size, tokenizer, max_length=512)\n",
    "training_losses, validation_losses, training_perplexities, validation_perplexities = train_and_validate(model, recipes, tokenizer, device, params={})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T01:05:49.132635Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x600 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_validation_curves(training_losses, validation_losses, training_perplexities, validation_perplexities)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T01:13:13.789043Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Example: Using pretrained GPT-2 with Cosine Similarity for Recipe Generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "3'th index 1024 of condition tensor does not match the other tensors",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[65], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m tfidf_vectorizer, tfidf_matrix \u001B[38;5;241m=\u001B[39m prepare_similarity_matrix(recipes)\n\u001B[0;32m----> 3\u001B[0m recipe_text \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_recipe_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_ingredients\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecipes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtfidf_vectorizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtfidf_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(recipe_text)\n",
      "Cell \u001B[0;32mIn[34], line 38\u001B[0m, in \u001B[0;36mgenerate_recipe_text\u001B[0;34m(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix, model, tokenizer)\u001B[0m\n\u001B[1;32m     36\u001B[0m attention_mask \u001B[38;5;241m=\u001B[39m encoded[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m     37\u001B[0m pad_token_id \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mpad_token_id\n\u001B[0;32m---> 38\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1024\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_return_sequences\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mno_repeat_ngram_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m generated_text \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Remove repetitions from the directions in the generated text\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/generation/utils.py:1479\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1462\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massisted_decoding(\n\u001B[1;32m   1463\u001B[0m         input_ids,\n\u001B[1;32m   1464\u001B[0m         candidate_generator\u001B[38;5;241m=\u001B[39mcandidate_generator,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1475\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1476\u001B[0m     )\n\u001B[1;32m   1477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mGREEDY_SEARCH:\n\u001B[1;32m   1478\u001B[0m     \u001B[38;5;66;03m# 11. run greedy search\u001B[39;00m\n\u001B[0;32m-> 1479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgreedy_search\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_logits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepared_stopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m        \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m generation_mode \u001B[38;5;241m==\u001B[39m GenerationMode\u001B[38;5;241m.\u001B[39mCONTRASTIVE_SEARCH:\n\u001B[1;32m   1493\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/generation/utils.py:2340\u001B[0m, in \u001B[0;36mGenerationMixin.greedy_search\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   2337\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m   2339\u001B[0m \u001B[38;5;66;03m# forward pass to get next token\u001B[39;00m\n\u001B[0;32m-> 2340\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2341\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2342\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2343\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2344\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2345\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[1;32m   2348\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# don't waste resources running the code we don't need\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:1074\u001B[0m, in \u001B[0;36mGPT2LMHeadModel.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1066\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1067\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1068\u001B[0m \u001B[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001B[39;00m\n\u001B[1;32m   1069\u001B[0m \u001B[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001B[39;00m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001B[39;00m\n\u001B[1;32m   1071\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1072\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1074\u001B[0m transformer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1088\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1089\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m transformer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1091\u001B[0m \u001B[38;5;66;03m# Set device for model parallelism\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:888\u001B[0m, in \u001B[0;36mGPT2Model.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    876\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    877\u001B[0m         block\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    878\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    885\u001B[0m         output_attentions,\n\u001B[1;32m    886\u001B[0m     )\n\u001B[1;32m    887\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 888\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_past\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_past\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    896\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    897\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    899\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:390\u001B[0m, in \u001B[0;36mGPT2Block.forward\u001B[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    388\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m    389\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_1(hidden_states)\n\u001B[0;32m--> 390\u001B[0m attn_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_past\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_past\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    398\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_outputs[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# output_attn: a, present, (attentions)\u001B[39;00m\n\u001B[1;32m    399\u001B[0m outputs \u001B[38;5;241m=\u001B[39m attn_outputs[\u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:331\u001B[0m, in \u001B[0;36mGPT2Attention.forward\u001B[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    329\u001B[0m     attn_output, attn_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 331\u001B[0m     attn_output, attn_weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_attn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    333\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_heads(attn_output, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\n\u001B[1;32m    334\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc_proj(attn_output)\n",
      "File \u001B[0;32m/Applications/anaconda3/envs/p2r/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:202\u001B[0m, in \u001B[0;36mGPT2Attention._attn\u001B[0;34m(self, query, key, value, attention_mask, head_mask)\u001B[0m\n\u001B[1;32m    199\u001B[0m     \u001B[38;5;66;03m# Need to be a tensor, otherwise we get error: `RuntimeError: expected scalar type float but found double`.\u001B[39;00m\n\u001B[1;32m    200\u001B[0m     \u001B[38;5;66;03m# Need to be on the same device, otherwise `RuntimeError: ..., x and y to be on the same device`\u001B[39;00m\n\u001B[1;32m    201\u001B[0m     mask_value \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfull([], mask_value, dtype\u001B[38;5;241m=\u001B[39mattn_weights\u001B[38;5;241m.\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mattn_weights\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 202\u001B[0m     attn_weights \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattn_weights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattn_weights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask_value\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;66;03m# Apply the attention mask\u001B[39;00m\n\u001B[1;32m    206\u001B[0m     attn_weights \u001B[38;5;241m=\u001B[39m attn_weights \u001B[38;5;241m+\u001B[39m attention_mask\n",
      "\u001B[0;31mRuntimeError\u001B[0m: 3'th index 1024 of condition tensor does not match the other tensors"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer, tfidf_matrix = prepare_similarity_matrix(recipes)\n",
    "\n",
    "recipe_text = generate_recipe_text(user_ingredients, recipes, tfidf_vectorizer, tfidf_matrix, model, tokenizer)\n",
    "print(recipe_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T01:13:30.401790Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-p2r-py",
   "language": "python",
   "display_name": "Python [conda env:p2r] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
